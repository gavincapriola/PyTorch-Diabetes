{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gavincapriola/PyTorch-Diabetes/blob/main/Diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tP2BcEILoLB"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLbPGJAWifUF",
        "outputId": "3ccf0eb7-4f7b-4b78-dfbb-bf5392451940"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.0+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.0%2Bcu101-cp38-cp38-linux_x86_64.whl (703.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m703.8/703.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.6.0+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.0%2Bcu101-cp38-cp38-linux_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from torch==1.5.0+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.5.0+cu101) (1.21.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.6.0+cu101) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.5.0+cu101 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.5.0+cu101 which is incompatible.\n",
            "fastai 2.7.10 requires torch<1.14,>=1.7, but you have torch 1.5.0+cu101 which is incompatible.\n",
            "fastai 2.7.10 requires torchvision>=0.8.2, but you have torchvision 0.6.0+cu101 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.5.0+cu101 torchvision-0.6.0+cu101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b85d_o8BdFub",
        "outputId": "a906ebf4-0cad-4c9b-9f5d-13bb70d35858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.5.0+cu101'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1WlABbCcw2B"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch.nn as nn"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFSnAUTVQN2j"
      },
      "source": [
        "diabetes = pd.read_csv('diabetes.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIoAdvbMuaUD",
        "outputId": "55ce23f5-0c2b-4072-975b-06210df38fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "diabetes.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee99e06d-6fa7-4043-8eb8-41c4a12dc20b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee99e06d-6fa7-4043-8eb8-41c4a12dc20b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ee99e06d-6fa7-4043-8eb8-41c4a12dc20b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ee99e06d-6fa7-4043-8eb8-41c4a12dc20b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2L0Zo3oQg66",
        "outputId": "973d7ba2-fab8-4b03-9100-68a5caf9f55b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputs = diabetes.iloc[:, 0:8].values\n",
        "inputs.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw6crTDBfaLl",
        "outputId": "d6939a04-2966-4368-d171-5ed6e7301717",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputs"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKVjNkwkumY7"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "inputs = scaler.fit_transform(inputs)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk9mvY2AuvJq",
        "outputId": "f7123e06-2df2-46e5-b839-d19faa509c77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputs"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwoclkDjQq-6",
        "outputId": "e58b059c-60df-4d1c-b125-c733dbbeb195",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "outputs = diabetes.iloc[:,8].values\n",
        "outputs"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX9ZDhUMgBsv"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size = 0.20)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SEVQyX9gR4O",
        "outputId": "bbb86988-b64f-418e-b8b9-940b4c1f8682",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(614, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKyN_plmgZzH",
        "outputId": "bc5b52bb-991b-4154-ae36-056aed9163c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(154, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72uvlxJrOuWd"
      },
      "source": [
        "## Data transformation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk5Gjgb7hBCo",
        "outputId": "da6dca88-80a5-46cf-c14b-3d08574cad27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqPER9AYhTpt"
      },
      "source": [
        "X_train = torch.tensor(X_train, dtype=torch.float)\n",
        "y_train = torch.tensor(y_train, dtype = torch.float)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-2HrvEJh5Km",
        "outputId": "56bf012a-2a2f-4f7b-835c-e2bf82fa21b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__6a-iZhiJVI"
      },
      "source": [
        "dataset = torch.utils.data.TensorDataset(X_train, y_train)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0sP_kvViZJl",
        "outputId": "8a8dfafa-1b9e-42f8-d4fd-f3824bd555ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(dataset)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataset.TensorDataset"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dIWzA4wihKD"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=10)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGDLesyDQpIb"
      },
      "source": [
        "## Neural network structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaSPjUFhatlQ",
        "outputId": "6302b463-09bc-4c6e-b449-c73bc988c28f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(8 + 1) / 2"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.5"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FAFgY56jmdG"
      },
      "source": [
        "# 8 -> 5 -> 5 -> 1\n",
        "network = nn.Sequential(nn.Linear(8, 5),\n",
        "                          nn.Sigmoid(),\n",
        "                          nn.Linear(5, 5),\n",
        "                          nn.Sigmoid(),\n",
        "                          nn.Linear(5, 1),\n",
        "                          nn.Sigmoid())"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixwI_mhZlDVW",
        "outputId": "02b3d29c-a491-46d9-bd12-2a591c6c2d9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "network.parameters"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of Sequential(\n",
              "  (0): Linear(in_features=8, out_features=5, bias=True)\n",
              "  (1): Sigmoid()\n",
              "  (2): Linear(in_features=5, out_features=5, bias=True)\n",
              "  (3): Sigmoid()\n",
              "  (4): Linear(in_features=5, out_features=1, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--bNcvlplMh9"
      },
      "source": [
        "loss_function = nn.BCELoss()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um6Tr3s_lXHK"
      },
      "source": [
        "optimizer = torch.optim.Adam(network.parameters(), lr=0.01)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exieZFSam_eI",
        "outputId": "a9734904-505b-43a2-f1a3-64298a97863b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 2000\n",
        "for epoch in range(epochs):\n",
        "  running_loss = 0.\n",
        "\n",
        "  for data in train_loader:\n",
        "    inputs, outputs = data\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    predictions = network.forward(inputs)\n",
        "    loss = loss_function(predictions, outputs)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "  print('Epoch %3d: loss %.5f' % (epoch+1, running_loss/len(train_loader)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   1: loss 0.65543\n",
            "Epoch   2: loss 0.65436\n",
            "Epoch   3: loss 0.65059\n",
            "Epoch   4: loss 0.64332\n",
            "Epoch   5: loss 0.62949\n",
            "Epoch   6: loss 0.60743\n",
            "Epoch   7: loss 0.58187\n",
            "Epoch   8: loss 0.56008\n",
            "Epoch   9: loss 0.54404\n",
            "Epoch  10: loss 0.53226\n",
            "Epoch  11: loss 0.52323\n",
            "Epoch  12: loss 0.51605\n",
            "Epoch  13: loss 0.51020\n",
            "Epoch  14: loss 0.50532\n",
            "Epoch  15: loss 0.50118\n",
            "Epoch  16: loss 0.49762\n",
            "Epoch  17: loss 0.49453\n",
            "Epoch  18: loss 0.49183\n",
            "Epoch  19: loss 0.48945\n",
            "Epoch  20: loss 0.48735\n",
            "Epoch  21: loss 0.48550\n",
            "Epoch  22: loss 0.48385\n",
            "Epoch  23: loss 0.48237\n",
            "Epoch  24: loss 0.48104\n",
            "Epoch  25: loss 0.47983\n",
            "Epoch  26: loss 0.47871\n",
            "Epoch  27: loss 0.47768\n",
            "Epoch  28: loss 0.47671\n",
            "Epoch  29: loss 0.47580\n",
            "Epoch  30: loss 0.47493\n",
            "Epoch  31: loss 0.47411\n",
            "Epoch  32: loss 0.47332\n",
            "Epoch  33: loss 0.47256\n",
            "Epoch  34: loss 0.47183\n",
            "Epoch  35: loss 0.47112\n",
            "Epoch  36: loss 0.47044\n",
            "Epoch  37: loss 0.46979\n",
            "Epoch  38: loss 0.46915\n",
            "Epoch  39: loss 0.46854\n",
            "Epoch  40: loss 0.46795\n",
            "Epoch  41: loss 0.46738\n",
            "Epoch  42: loss 0.46682\n",
            "Epoch  43: loss 0.46629\n",
            "Epoch  44: loss 0.46578\n",
            "Epoch  45: loss 0.46529\n",
            "Epoch  46: loss 0.46481\n",
            "Epoch  47: loss 0.46436\n",
            "Epoch  48: loss 0.46392\n",
            "Epoch  49: loss 0.46351\n",
            "Epoch  50: loss 0.46311\n",
            "Epoch  51: loss 0.46273\n",
            "Epoch  52: loss 0.46236\n",
            "Epoch  53: loss 0.46201\n",
            "Epoch  54: loss 0.46168\n",
            "Epoch  55: loss 0.46137\n",
            "Epoch  56: loss 0.46106\n",
            "Epoch  57: loss 0.46078\n",
            "Epoch  58: loss 0.46050\n",
            "Epoch  59: loss 0.46024\n",
            "Epoch  60: loss 0.45999\n",
            "Epoch  61: loss 0.45976\n",
            "Epoch  62: loss 0.45953\n",
            "Epoch  63: loss 0.45932\n",
            "Epoch  64: loss 0.45911\n",
            "Epoch  65: loss 0.45891\n",
            "Epoch  66: loss 0.45873\n",
            "Epoch  67: loss 0.45855\n",
            "Epoch  68: loss 0.45837\n",
            "Epoch  69: loss 0.45821\n",
            "Epoch  70: loss 0.45805\n",
            "Epoch  71: loss 0.45790\n",
            "Epoch  72: loss 0.45775\n",
            "Epoch  73: loss 0.45761\n",
            "Epoch  74: loss 0.45747\n",
            "Epoch  75: loss 0.45734\n",
            "Epoch  76: loss 0.45721\n",
            "Epoch  77: loss 0.45709\n",
            "Epoch  78: loss 0.45697\n",
            "Epoch  79: loss 0.45685\n",
            "Epoch  80: loss 0.45674\n",
            "Epoch  81: loss 0.45663\n",
            "Epoch  82: loss 0.45652\n",
            "Epoch  83: loss 0.45642\n",
            "Epoch  84: loss 0.45632\n",
            "Epoch  85: loss 0.45622\n",
            "Epoch  86: loss 0.45612\n",
            "Epoch  87: loss 0.45602\n",
            "Epoch  88: loss 0.45593\n",
            "Epoch  89: loss 0.45584\n",
            "Epoch  90: loss 0.45575\n",
            "Epoch  91: loss 0.45566\n",
            "Epoch  92: loss 0.45558\n",
            "Epoch  93: loss 0.45549\n",
            "Epoch  94: loss 0.45541\n",
            "Epoch  95: loss 0.45533\n",
            "Epoch  96: loss 0.45525\n",
            "Epoch  97: loss 0.45517\n",
            "Epoch  98: loss 0.45509\n",
            "Epoch  99: loss 0.45501\n",
            "Epoch 100: loss 0.45493\n",
            "Epoch 101: loss 0.45486\n",
            "Epoch 102: loss 0.45478\n",
            "Epoch 103: loss 0.45471\n",
            "Epoch 104: loss 0.45463\n",
            "Epoch 105: loss 0.45456\n",
            "Epoch 106: loss 0.45449\n",
            "Epoch 107: loss 0.45441\n",
            "Epoch 108: loss 0.45434\n",
            "Epoch 109: loss 0.45427\n",
            "Epoch 110: loss 0.45420\n",
            "Epoch 111: loss 0.45413\n",
            "Epoch 112: loss 0.45406\n",
            "Epoch 113: loss 0.45399\n",
            "Epoch 114: loss 0.45392\n",
            "Epoch 115: loss 0.45385\n",
            "Epoch 116: loss 0.45379\n",
            "Epoch 117: loss 0.45372\n",
            "Epoch 118: loss 0.45365\n",
            "Epoch 119: loss 0.45358\n",
            "Epoch 120: loss 0.45352\n",
            "Epoch 121: loss 0.45345\n",
            "Epoch 122: loss 0.45338\n",
            "Epoch 123: loss 0.45331\n",
            "Epoch 124: loss 0.45325\n",
            "Epoch 125: loss 0.45318\n",
            "Epoch 126: loss 0.45311\n",
            "Epoch 127: loss 0.45305\n",
            "Epoch 128: loss 0.45298\n",
            "Epoch 129: loss 0.45291\n",
            "Epoch 130: loss 0.45285\n",
            "Epoch 131: loss 0.45278\n",
            "Epoch 132: loss 0.45272\n",
            "Epoch 133: loss 0.45265\n",
            "Epoch 134: loss 0.45258\n",
            "Epoch 135: loss 0.45252\n",
            "Epoch 136: loss 0.45245\n",
            "Epoch 137: loss 0.45239\n",
            "Epoch 138: loss 0.45232\n",
            "Epoch 139: loss 0.45225\n",
            "Epoch 140: loss 0.45219\n",
            "Epoch 141: loss 0.45212\n",
            "Epoch 142: loss 0.45206\n",
            "Epoch 143: loss 0.45199\n",
            "Epoch 144: loss 0.45193\n",
            "Epoch 145: loss 0.45186\n",
            "Epoch 146: loss 0.45180\n",
            "Epoch 147: loss 0.45173\n",
            "Epoch 148: loss 0.45167\n",
            "Epoch 149: loss 0.45161\n",
            "Epoch 150: loss 0.45154\n",
            "Epoch 151: loss 0.45148\n",
            "Epoch 152: loss 0.45141\n",
            "Epoch 153: loss 0.45135\n",
            "Epoch 154: loss 0.45129\n",
            "Epoch 155: loss 0.45122\n",
            "Epoch 156: loss 0.45116\n",
            "Epoch 157: loss 0.45110\n",
            "Epoch 158: loss 0.45103\n",
            "Epoch 159: loss 0.45097\n",
            "Epoch 160: loss 0.45091\n",
            "Epoch 161: loss 0.45084\n",
            "Epoch 162: loss 0.45078\n",
            "Epoch 163: loss 0.45072\n",
            "Epoch 164: loss 0.45066\n",
            "Epoch 165: loss 0.45060\n",
            "Epoch 166: loss 0.45054\n",
            "Epoch 167: loss 0.45047\n",
            "Epoch 168: loss 0.45041\n",
            "Epoch 169: loss 0.45035\n",
            "Epoch 170: loss 0.45029\n",
            "Epoch 171: loss 0.45023\n",
            "Epoch 172: loss 0.45017\n",
            "Epoch 173: loss 0.45011\n",
            "Epoch 174: loss 0.45005\n",
            "Epoch 175: loss 0.44999\n",
            "Epoch 176: loss 0.44993\n",
            "Epoch 177: loss 0.44987\n",
            "Epoch 178: loss 0.44981\n",
            "Epoch 179: loss 0.44975\n",
            "Epoch 180: loss 0.44969\n",
            "Epoch 181: loss 0.44964\n",
            "Epoch 182: loss 0.44958\n",
            "Epoch 183: loss 0.44952\n",
            "Epoch 184: loss 0.44946\n",
            "Epoch 185: loss 0.44940\n",
            "Epoch 186: loss 0.44934\n",
            "Epoch 187: loss 0.44929\n",
            "Epoch 188: loss 0.44923\n",
            "Epoch 189: loss 0.44917\n",
            "Epoch 190: loss 0.44911\n",
            "Epoch 191: loss 0.44906\n",
            "Epoch 192: loss 0.44900\n",
            "Epoch 193: loss 0.44894\n",
            "Epoch 194: loss 0.44889\n",
            "Epoch 195: loss 0.44883\n",
            "Epoch 196: loss 0.44877\n",
            "Epoch 197: loss 0.44872\n",
            "Epoch 198: loss 0.44866\n",
            "Epoch 199: loss 0.44860\n",
            "Epoch 200: loss 0.44855\n",
            "Epoch 201: loss 0.44849\n",
            "Epoch 202: loss 0.44843\n",
            "Epoch 203: loss 0.44838\n",
            "Epoch 204: loss 0.44832\n",
            "Epoch 205: loss 0.44827\n",
            "Epoch 206: loss 0.44821\n",
            "Epoch 207: loss 0.44815\n",
            "Epoch 208: loss 0.44810\n",
            "Epoch 209: loss 0.44804\n",
            "Epoch 210: loss 0.44799\n",
            "Epoch 211: loss 0.44793\n",
            "Epoch 212: loss 0.44787\n",
            "Epoch 213: loss 0.44782\n",
            "Epoch 214: loss 0.44776\n",
            "Epoch 215: loss 0.44771\n",
            "Epoch 216: loss 0.44765\n",
            "Epoch 217: loss 0.44760\n",
            "Epoch 218: loss 0.44754\n",
            "Epoch 219: loss 0.44749\n",
            "Epoch 220: loss 0.44743\n",
            "Epoch 221: loss 0.44738\n",
            "Epoch 222: loss 0.44732\n",
            "Epoch 223: loss 0.44727\n",
            "Epoch 224: loss 0.44721\n",
            "Epoch 225: loss 0.44716\n",
            "Epoch 226: loss 0.44710\n",
            "Epoch 227: loss 0.44705\n",
            "Epoch 228: loss 0.44699\n",
            "Epoch 229: loss 0.44694\n",
            "Epoch 230: loss 0.44688\n",
            "Epoch 231: loss 0.44683\n",
            "Epoch 232: loss 0.44677\n",
            "Epoch 233: loss 0.44672\n",
            "Epoch 234: loss 0.44666\n",
            "Epoch 235: loss 0.44661\n",
            "Epoch 236: loss 0.44656\n",
            "Epoch 237: loss 0.44650\n",
            "Epoch 238: loss 0.44645\n",
            "Epoch 239: loss 0.44639\n",
            "Epoch 240: loss 0.44634\n",
            "Epoch 241: loss 0.44628\n",
            "Epoch 242: loss 0.44623\n",
            "Epoch 243: loss 0.44617\n",
            "Epoch 244: loss 0.44612\n",
            "Epoch 245: loss 0.44607\n",
            "Epoch 246: loss 0.44601\n",
            "Epoch 247: loss 0.44596\n",
            "Epoch 248: loss 0.44590\n",
            "Epoch 249: loss 0.44585\n",
            "Epoch 250: loss 0.44579\n",
            "Epoch 251: loss 0.44574\n",
            "Epoch 252: loss 0.44569\n",
            "Epoch 253: loss 0.44563\n",
            "Epoch 254: loss 0.44558\n",
            "Epoch 255: loss 0.44552\n",
            "Epoch 256: loss 0.44547\n",
            "Epoch 257: loss 0.44541\n",
            "Epoch 258: loss 0.44536\n",
            "Epoch 259: loss 0.44531\n",
            "Epoch 260: loss 0.44525\n",
            "Epoch 261: loss 0.44520\n",
            "Epoch 262: loss 0.44514\n",
            "Epoch 263: loss 0.44509\n",
            "Epoch 264: loss 0.44504\n",
            "Epoch 265: loss 0.44498\n",
            "Epoch 266: loss 0.44493\n",
            "Epoch 267: loss 0.44487\n",
            "Epoch 268: loss 0.44482\n",
            "Epoch 269: loss 0.44476\n",
            "Epoch 270: loss 0.44471\n",
            "Epoch 271: loss 0.44466\n",
            "Epoch 272: loss 0.44460\n",
            "Epoch 273: loss 0.44455\n",
            "Epoch 274: loss 0.44449\n",
            "Epoch 275: loss 0.44444\n",
            "Epoch 276: loss 0.44438\n",
            "Epoch 277: loss 0.44433\n",
            "Epoch 278: loss 0.44427\n",
            "Epoch 279: loss 0.44422\n",
            "Epoch 280: loss 0.44416\n",
            "Epoch 281: loss 0.44411\n",
            "Epoch 282: loss 0.44405\n",
            "Epoch 283: loss 0.44400\n",
            "Epoch 284: loss 0.44395\n",
            "Epoch 285: loss 0.44389\n",
            "Epoch 286: loss 0.44383\n",
            "Epoch 287: loss 0.44378\n",
            "Epoch 288: loss 0.44372\n",
            "Epoch 289: loss 0.44367\n",
            "Epoch 290: loss 0.44361\n",
            "Epoch 291: loss 0.44356\n",
            "Epoch 292: loss 0.44350\n",
            "Epoch 293: loss 0.44345\n",
            "Epoch 294: loss 0.44339\n",
            "Epoch 295: loss 0.44334\n",
            "Epoch 296: loss 0.44328\n",
            "Epoch 297: loss 0.44322\n",
            "Epoch 298: loss 0.44317\n",
            "Epoch 299: loss 0.44311\n",
            "Epoch 300: loss 0.44306\n",
            "Epoch 301: loss 0.44300\n",
            "Epoch 302: loss 0.44294\n",
            "Epoch 303: loss 0.44289\n",
            "Epoch 304: loss 0.44283\n",
            "Epoch 305: loss 0.44277\n",
            "Epoch 306: loss 0.44272\n",
            "Epoch 307: loss 0.44266\n",
            "Epoch 308: loss 0.44260\n",
            "Epoch 309: loss 0.44255\n",
            "Epoch 310: loss 0.44249\n",
            "Epoch 311: loss 0.44243\n",
            "Epoch 312: loss 0.44238\n",
            "Epoch 313: loss 0.44232\n",
            "Epoch 314: loss 0.44226\n",
            "Epoch 315: loss 0.44220\n",
            "Epoch 316: loss 0.44215\n",
            "Epoch 317: loss 0.44209\n",
            "Epoch 318: loss 0.44203\n",
            "Epoch 319: loss 0.44197\n",
            "Epoch 320: loss 0.44192\n",
            "Epoch 321: loss 0.44186\n",
            "Epoch 322: loss 0.44180\n",
            "Epoch 323: loss 0.44174\n",
            "Epoch 324: loss 0.44168\n",
            "Epoch 325: loss 0.44162\n",
            "Epoch 326: loss 0.44157\n",
            "Epoch 327: loss 0.44151\n",
            "Epoch 328: loss 0.44145\n",
            "Epoch 329: loss 0.44139\n",
            "Epoch 330: loss 0.44133\n",
            "Epoch 331: loss 0.44127\n",
            "Epoch 332: loss 0.44121\n",
            "Epoch 333: loss 0.44116\n",
            "Epoch 334: loss 0.44110\n",
            "Epoch 335: loss 0.44104\n",
            "Epoch 336: loss 0.44098\n",
            "Epoch 337: loss 0.44092\n",
            "Epoch 338: loss 0.44086\n",
            "Epoch 339: loss 0.44080\n",
            "Epoch 340: loss 0.44074\n",
            "Epoch 341: loss 0.44068\n",
            "Epoch 342: loss 0.44062\n",
            "Epoch 343: loss 0.44056\n",
            "Epoch 344: loss 0.44050\n",
            "Epoch 345: loss 0.44044\n",
            "Epoch 346: loss 0.44038\n",
            "Epoch 347: loss 0.44032\n",
            "Epoch 348: loss 0.44026\n",
            "Epoch 349: loss 0.44020\n",
            "Epoch 350: loss 0.44014\n",
            "Epoch 351: loss 0.44008\n",
            "Epoch 352: loss 0.44002\n",
            "Epoch 353: loss 0.43996\n",
            "Epoch 354: loss 0.43990\n",
            "Epoch 355: loss 0.43984\n",
            "Epoch 356: loss 0.43978\n",
            "Epoch 357: loss 0.43972\n",
            "Epoch 358: loss 0.43965\n",
            "Epoch 359: loss 0.43959\n",
            "Epoch 360: loss 0.43953\n",
            "Epoch 361: loss 0.43947\n",
            "Epoch 362: loss 0.43941\n",
            "Epoch 363: loss 0.43935\n",
            "Epoch 364: loss 0.43929\n",
            "Epoch 365: loss 0.43922\n",
            "Epoch 366: loss 0.43916\n",
            "Epoch 367: loss 0.43910\n",
            "Epoch 368: loss 0.43904\n",
            "Epoch 369: loss 0.43897\n",
            "Epoch 370: loss 0.43891\n",
            "Epoch 371: loss 0.43885\n",
            "Epoch 372: loss 0.43879\n",
            "Epoch 373: loss 0.43872\n",
            "Epoch 374: loss 0.43866\n",
            "Epoch 375: loss 0.43860\n",
            "Epoch 376: loss 0.43853\n",
            "Epoch 377: loss 0.43847\n",
            "Epoch 378: loss 0.43841\n",
            "Epoch 379: loss 0.43834\n",
            "Epoch 380: loss 0.43828\n",
            "Epoch 381: loss 0.43822\n",
            "Epoch 382: loss 0.43815\n",
            "Epoch 383: loss 0.43809\n",
            "Epoch 384: loss 0.43803\n",
            "Epoch 385: loss 0.43796\n",
            "Epoch 386: loss 0.43790\n",
            "Epoch 387: loss 0.43783\n",
            "Epoch 388: loss 0.43777\n",
            "Epoch 389: loss 0.43770\n",
            "Epoch 390: loss 0.43764\n",
            "Epoch 391: loss 0.43758\n",
            "Epoch 392: loss 0.43751\n",
            "Epoch 393: loss 0.43745\n",
            "Epoch 394: loss 0.43738\n",
            "Epoch 395: loss 0.43732\n",
            "Epoch 396: loss 0.43725\n",
            "Epoch 397: loss 0.43719\n",
            "Epoch 398: loss 0.43712\n",
            "Epoch 399: loss 0.43706\n",
            "Epoch 400: loss 0.43699\n",
            "Epoch 401: loss 0.43692\n",
            "Epoch 402: loss 0.43686\n",
            "Epoch 403: loss 0.43679\n",
            "Epoch 404: loss 0.43673\n",
            "Epoch 405: loss 0.43666\n",
            "Epoch 406: loss 0.43660\n",
            "Epoch 407: loss 0.43653\n",
            "Epoch 408: loss 0.43647\n",
            "Epoch 409: loss 0.43640\n",
            "Epoch 410: loss 0.43633\n",
            "Epoch 411: loss 0.43627\n",
            "Epoch 412: loss 0.43620\n",
            "Epoch 413: loss 0.43614\n",
            "Epoch 414: loss 0.43607\n",
            "Epoch 415: loss 0.43601\n",
            "Epoch 416: loss 0.43594\n",
            "Epoch 417: loss 0.43588\n",
            "Epoch 418: loss 0.43581\n",
            "Epoch 419: loss 0.43574\n",
            "Epoch 420: loss 0.43568\n",
            "Epoch 421: loss 0.43561\n",
            "Epoch 422: loss 0.43555\n",
            "Epoch 423: loss 0.43548\n",
            "Epoch 424: loss 0.43542\n",
            "Epoch 425: loss 0.43535\n",
            "Epoch 426: loss 0.43529\n",
            "Epoch 427: loss 0.43522\n",
            "Epoch 428: loss 0.43516\n",
            "Epoch 429: loss 0.43509\n",
            "Epoch 430: loss 0.43503\n",
            "Epoch 431: loss 0.43496\n",
            "Epoch 432: loss 0.43490\n",
            "Epoch 433: loss 0.43484\n",
            "Epoch 434: loss 0.43477\n",
            "Epoch 435: loss 0.43471\n",
            "Epoch 436: loss 0.43465\n",
            "Epoch 437: loss 0.43458\n",
            "Epoch 438: loss 0.43452\n",
            "Epoch 439: loss 0.43446\n",
            "Epoch 440: loss 0.43439\n",
            "Epoch 441: loss 0.43433\n",
            "Epoch 442: loss 0.43427\n",
            "Epoch 443: loss 0.43421\n",
            "Epoch 444: loss 0.43414\n",
            "Epoch 445: loss 0.43408\n",
            "Epoch 446: loss 0.43402\n",
            "Epoch 447: loss 0.43396\n",
            "Epoch 448: loss 0.43390\n",
            "Epoch 449: loss 0.43384\n",
            "Epoch 450: loss 0.43378\n",
            "Epoch 451: loss 0.43371\n",
            "Epoch 452: loss 0.43365\n",
            "Epoch 453: loss 0.43359\n",
            "Epoch 454: loss 0.43353\n",
            "Epoch 455: loss 0.43348\n",
            "Epoch 456: loss 0.43342\n",
            "Epoch 457: loss 0.43336\n",
            "Epoch 458: loss 0.43330\n",
            "Epoch 459: loss 0.43324\n",
            "Epoch 460: loss 0.43318\n",
            "Epoch 461: loss 0.43312\n",
            "Epoch 462: loss 0.43307\n",
            "Epoch 463: loss 0.43301\n",
            "Epoch 464: loss 0.43295\n",
            "Epoch 465: loss 0.43290\n",
            "Epoch 466: loss 0.43284\n",
            "Epoch 467: loss 0.43278\n",
            "Epoch 468: loss 0.43273\n",
            "Epoch 469: loss 0.43267\n",
            "Epoch 470: loss 0.43262\n",
            "Epoch 471: loss 0.43256\n",
            "Epoch 472: loss 0.43251\n",
            "Epoch 473: loss 0.43245\n",
            "Epoch 474: loss 0.43240\n",
            "Epoch 475: loss 0.43235\n",
            "Epoch 476: loss 0.43229\n",
            "Epoch 477: loss 0.43224\n",
            "Epoch 478: loss 0.43219\n",
            "Epoch 479: loss 0.43213\n",
            "Epoch 480: loss 0.43208\n",
            "Epoch 481: loss 0.43203\n",
            "Epoch 482: loss 0.43198\n",
            "Epoch 483: loss 0.43193\n",
            "Epoch 484: loss 0.43188\n",
            "Epoch 485: loss 0.43183\n",
            "Epoch 486: loss 0.43178\n",
            "Epoch 487: loss 0.43173\n",
            "Epoch 488: loss 0.43168\n",
            "Epoch 489: loss 0.43163\n",
            "Epoch 490: loss 0.43158\n",
            "Epoch 491: loss 0.43153\n",
            "Epoch 492: loss 0.43148\n",
            "Epoch 493: loss 0.43143\n",
            "Epoch 494: loss 0.43138\n",
            "Epoch 495: loss 0.43134\n",
            "Epoch 496: loss 0.43129\n",
            "Epoch 497: loss 0.43124\n",
            "Epoch 498: loss 0.43120\n",
            "Epoch 499: loss 0.43115\n",
            "Epoch 500: loss 0.43110\n",
            "Epoch 501: loss 0.43106\n",
            "Epoch 502: loss 0.43101\n",
            "Epoch 503: loss 0.43097\n",
            "Epoch 504: loss 0.43092\n",
            "Epoch 505: loss 0.43088\n",
            "Epoch 506: loss 0.43083\n",
            "Epoch 507: loss 0.43079\n",
            "Epoch 508: loss 0.43075\n",
            "Epoch 509: loss 0.43070\n",
            "Epoch 510: loss 0.43066\n",
            "Epoch 511: loss 0.43062\n",
            "Epoch 512: loss 0.43057\n",
            "Epoch 513: loss 0.43053\n",
            "Epoch 514: loss 0.43049\n",
            "Epoch 515: loss 0.43045\n",
            "Epoch 516: loss 0.43041\n",
            "Epoch 517: loss 0.43036\n",
            "Epoch 518: loss 0.43032\n",
            "Epoch 519: loss 0.43028\n",
            "Epoch 520: loss 0.43024\n",
            "Epoch 521: loss 0.43020\n",
            "Epoch 522: loss 0.43016\n",
            "Epoch 523: loss 0.43012\n",
            "Epoch 524: loss 0.43008\n",
            "Epoch 525: loss 0.43004\n",
            "Epoch 526: loss 0.43000\n",
            "Epoch 527: loss 0.42996\n",
            "Epoch 528: loss 0.42992\n",
            "Epoch 529: loss 0.42989\n",
            "Epoch 530: loss 0.42985\n",
            "Epoch 531: loss 0.42981\n",
            "Epoch 532: loss 0.42977\n",
            "Epoch 533: loss 0.42973\n",
            "Epoch 534: loss 0.42970\n",
            "Epoch 535: loss 0.42966\n",
            "Epoch 536: loss 0.42962\n",
            "Epoch 537: loss 0.42959\n",
            "Epoch 538: loss 0.42955\n",
            "Epoch 539: loss 0.42951\n",
            "Epoch 540: loss 0.42948\n",
            "Epoch 541: loss 0.42944\n",
            "Epoch 542: loss 0.42941\n",
            "Epoch 543: loss 0.42937\n",
            "Epoch 544: loss 0.42934\n",
            "Epoch 545: loss 0.42930\n",
            "Epoch 546: loss 0.42927\n",
            "Epoch 547: loss 0.42923\n",
            "Epoch 548: loss 0.42920\n",
            "Epoch 549: loss 0.42916\n",
            "Epoch 550: loss 0.42913\n",
            "Epoch 551: loss 0.42910\n",
            "Epoch 552: loss 0.42906\n",
            "Epoch 553: loss 0.42903\n",
            "Epoch 554: loss 0.42900\n",
            "Epoch 555: loss 0.42896\n",
            "Epoch 556: loss 0.42893\n",
            "Epoch 557: loss 0.42890\n",
            "Epoch 558: loss 0.42886\n",
            "Epoch 559: loss 0.42883\n",
            "Epoch 560: loss 0.42880\n",
            "Epoch 561: loss 0.42877\n",
            "Epoch 562: loss 0.42874\n",
            "Epoch 563: loss 0.42870\n",
            "Epoch 564: loss 0.42867\n",
            "Epoch 565: loss 0.42864\n",
            "Epoch 566: loss 0.42861\n",
            "Epoch 567: loss 0.42858\n",
            "Epoch 568: loss 0.42855\n",
            "Epoch 569: loss 0.42852\n",
            "Epoch 570: loss 0.42849\n",
            "Epoch 571: loss 0.42846\n",
            "Epoch 572: loss 0.42843\n",
            "Epoch 573: loss 0.42840\n",
            "Epoch 574: loss 0.42837\n",
            "Epoch 575: loss 0.42834\n",
            "Epoch 576: loss 0.42831\n",
            "Epoch 577: loss 0.42828\n",
            "Epoch 578: loss 0.42825\n",
            "Epoch 579: loss 0.42822\n",
            "Epoch 580: loss 0.42819\n",
            "Epoch 581: loss 0.42816\n",
            "Epoch 582: loss 0.42813\n",
            "Epoch 583: loss 0.42810\n",
            "Epoch 584: loss 0.42807\n",
            "Epoch 585: loss 0.42805\n",
            "Epoch 586: loss 0.42802\n",
            "Epoch 587: loss 0.42799\n",
            "Epoch 588: loss 0.42796\n",
            "Epoch 589: loss 0.42793\n",
            "Epoch 590: loss 0.42791\n",
            "Epoch 591: loss 0.42788\n",
            "Epoch 592: loss 0.42785\n",
            "Epoch 593: loss 0.42782\n",
            "Epoch 594: loss 0.42780\n",
            "Epoch 595: loss 0.42777\n",
            "Epoch 596: loss 0.42774\n",
            "Epoch 597: loss 0.42771\n",
            "Epoch 598: loss 0.42769\n",
            "Epoch 599: loss 0.42766\n",
            "Epoch 600: loss 0.42763\n",
            "Epoch 601: loss 0.42761\n",
            "Epoch 602: loss 0.42758\n",
            "Epoch 603: loss 0.42755\n",
            "Epoch 604: loss 0.42753\n",
            "Epoch 605: loss 0.42750\n",
            "Epoch 606: loss 0.42748\n",
            "Epoch 607: loss 0.42745\n",
            "Epoch 608: loss 0.42742\n",
            "Epoch 609: loss 0.42740\n",
            "Epoch 610: loss 0.42737\n",
            "Epoch 611: loss 0.42735\n",
            "Epoch 612: loss 0.42732\n",
            "Epoch 613: loss 0.42729\n",
            "Epoch 614: loss 0.42727\n",
            "Epoch 615: loss 0.42724\n",
            "Epoch 616: loss 0.42722\n",
            "Epoch 617: loss 0.42719\n",
            "Epoch 618: loss 0.42717\n",
            "Epoch 619: loss 0.42714\n",
            "Epoch 620: loss 0.42712\n",
            "Epoch 621: loss 0.42709\n",
            "Epoch 622: loss 0.42707\n",
            "Epoch 623: loss 0.42704\n",
            "Epoch 624: loss 0.42702\n",
            "Epoch 625: loss 0.42699\n",
            "Epoch 626: loss 0.42697\n",
            "Epoch 627: loss 0.42694\n",
            "Epoch 628: loss 0.42692\n",
            "Epoch 629: loss 0.42689\n",
            "Epoch 630: loss 0.42687\n",
            "Epoch 631: loss 0.42684\n",
            "Epoch 632: loss 0.42682\n",
            "Epoch 633: loss 0.42679\n",
            "Epoch 634: loss 0.42677\n",
            "Epoch 635: loss 0.42674\n",
            "Epoch 636: loss 0.42672\n",
            "Epoch 637: loss 0.42669\n",
            "Epoch 638: loss 0.42667\n",
            "Epoch 639: loss 0.42664\n",
            "Epoch 640: loss 0.42662\n",
            "Epoch 641: loss 0.42659\n",
            "Epoch 642: loss 0.42657\n",
            "Epoch 643: loss 0.42654\n",
            "Epoch 644: loss 0.42652\n",
            "Epoch 645: loss 0.42649\n",
            "Epoch 646: loss 0.42647\n",
            "Epoch 647: loss 0.42644\n",
            "Epoch 648: loss 0.42642\n",
            "Epoch 649: loss 0.42639\n",
            "Epoch 650: loss 0.42637\n",
            "Epoch 651: loss 0.42634\n",
            "Epoch 652: loss 0.42631\n",
            "Epoch 653: loss 0.42629\n",
            "Epoch 654: loss 0.42626\n",
            "Epoch 655: loss 0.42624\n",
            "Epoch 656: loss 0.42621\n",
            "Epoch 657: loss 0.42619\n",
            "Epoch 658: loss 0.42616\n",
            "Epoch 659: loss 0.42613\n",
            "Epoch 660: loss 0.42611\n",
            "Epoch 661: loss 0.42608\n",
            "Epoch 662: loss 0.42605\n",
            "Epoch 663: loss 0.42603\n",
            "Epoch 664: loss 0.42600\n",
            "Epoch 665: loss 0.42597\n",
            "Epoch 666: loss 0.42595\n",
            "Epoch 667: loss 0.42592\n",
            "Epoch 668: loss 0.42589\n",
            "Epoch 669: loss 0.42586\n",
            "Epoch 670: loss 0.42584\n",
            "Epoch 671: loss 0.42581\n",
            "Epoch 672: loss 0.42578\n",
            "Epoch 673: loss 0.42575\n",
            "Epoch 674: loss 0.42572\n",
            "Epoch 675: loss 0.42570\n",
            "Epoch 676: loss 0.42567\n",
            "Epoch 677: loss 0.42564\n",
            "Epoch 678: loss 0.42561\n",
            "Epoch 679: loss 0.42558\n",
            "Epoch 680: loss 0.42555\n",
            "Epoch 681: loss 0.42552\n",
            "Epoch 682: loss 0.42549\n",
            "Epoch 683: loss 0.42546\n",
            "Epoch 684: loss 0.42543\n",
            "Epoch 685: loss 0.42540\n",
            "Epoch 686: loss 0.42537\n",
            "Epoch 687: loss 0.42534\n",
            "Epoch 688: loss 0.42530\n",
            "Epoch 689: loss 0.42527\n",
            "Epoch 690: loss 0.42524\n",
            "Epoch 691: loss 0.42521\n",
            "Epoch 692: loss 0.42517\n",
            "Epoch 693: loss 0.42514\n",
            "Epoch 694: loss 0.42511\n",
            "Epoch 695: loss 0.42507\n",
            "Epoch 696: loss 0.42504\n",
            "Epoch 697: loss 0.42500\n",
            "Epoch 698: loss 0.42497\n",
            "Epoch 699: loss 0.42493\n",
            "Epoch 700: loss 0.42490\n",
            "Epoch 701: loss 0.42486\n",
            "Epoch 702: loss 0.42483\n",
            "Epoch 703: loss 0.42479\n",
            "Epoch 704: loss 0.42475\n",
            "Epoch 705: loss 0.42472\n",
            "Epoch 706: loss 0.42468\n",
            "Epoch 707: loss 0.42464\n",
            "Epoch 708: loss 0.42460\n",
            "Epoch 709: loss 0.42456\n",
            "Epoch 710: loss 0.42452\n",
            "Epoch 711: loss 0.42448\n",
            "Epoch 712: loss 0.42444\n",
            "Epoch 713: loss 0.42440\n",
            "Epoch 714: loss 0.42436\n",
            "Epoch 715: loss 0.42432\n",
            "Epoch 716: loss 0.42428\n",
            "Epoch 717: loss 0.42423\n",
            "Epoch 718: loss 0.42419\n",
            "Epoch 719: loss 0.42415\n",
            "Epoch 720: loss 0.42410\n",
            "Epoch 721: loss 0.42406\n",
            "Epoch 722: loss 0.42401\n",
            "Epoch 723: loss 0.42397\n",
            "Epoch 724: loss 0.42392\n",
            "Epoch 725: loss 0.42388\n",
            "Epoch 726: loss 0.42383\n",
            "Epoch 727: loss 0.42378\n",
            "Epoch 728: loss 0.42374\n",
            "Epoch 729: loss 0.42369\n",
            "Epoch 730: loss 0.42364\n",
            "Epoch 731: loss 0.42359\n",
            "Epoch 732: loss 0.42354\n",
            "Epoch 733: loss 0.42349\n",
            "Epoch 734: loss 0.42344\n",
            "Epoch 735: loss 0.42339\n",
            "Epoch 736: loss 0.42333\n",
            "Epoch 737: loss 0.42328\n",
            "Epoch 738: loss 0.42323\n",
            "Epoch 739: loss 0.42318\n",
            "Epoch 740: loss 0.42312\n",
            "Epoch 741: loss 0.42307\n",
            "Epoch 742: loss 0.42301\n",
            "Epoch 743: loss 0.42296\n",
            "Epoch 744: loss 0.42290\n",
            "Epoch 745: loss 0.42284\n",
            "Epoch 746: loss 0.42279\n",
            "Epoch 747: loss 0.42273\n",
            "Epoch 748: loss 0.42267\n",
            "Epoch 749: loss 0.42261\n",
            "Epoch 750: loss 0.42255\n",
            "Epoch 751: loss 0.42249\n",
            "Epoch 752: loss 0.42243\n",
            "Epoch 753: loss 0.42237\n",
            "Epoch 754: loss 0.42231\n",
            "Epoch 755: loss 0.42225\n",
            "Epoch 756: loss 0.42219\n",
            "Epoch 757: loss 0.42213\n",
            "Epoch 758: loss 0.42207\n",
            "Epoch 759: loss 0.42201\n",
            "Epoch 760: loss 0.42194\n",
            "Epoch 761: loss 0.42188\n",
            "Epoch 762: loss 0.42182\n",
            "Epoch 763: loss 0.42176\n",
            "Epoch 764: loss 0.42169\n",
            "Epoch 765: loss 0.42163\n",
            "Epoch 766: loss 0.42157\n",
            "Epoch 767: loss 0.42150\n",
            "Epoch 768: loss 0.42144\n",
            "Epoch 769: loss 0.42138\n",
            "Epoch 770: loss 0.42131\n",
            "Epoch 771: loss 0.42125\n",
            "Epoch 772: loss 0.42119\n",
            "Epoch 773: loss 0.42112\n",
            "Epoch 774: loss 0.42106\n",
            "Epoch 775: loss 0.42100\n",
            "Epoch 776: loss 0.42094\n",
            "Epoch 777: loss 0.42088\n",
            "Epoch 778: loss 0.42081\n",
            "Epoch 779: loss 0.42075\n",
            "Epoch 780: loss 0.42069\n",
            "Epoch 781: loss 0.42063\n",
            "Epoch 782: loss 0.42057\n",
            "Epoch 783: loss 0.42051\n",
            "Epoch 784: loss 0.42045\n",
            "Epoch 785: loss 0.42039\n",
            "Epoch 786: loss 0.42034\n",
            "Epoch 787: loss 0.42028\n",
            "Epoch 788: loss 0.42022\n",
            "Epoch 789: loss 0.42017\n",
            "Epoch 790: loss 0.42011\n",
            "Epoch 791: loss 0.42005\n",
            "Epoch 792: loss 0.42000\n",
            "Epoch 793: loss 0.41995\n",
            "Epoch 794: loss 0.41989\n",
            "Epoch 795: loss 0.41984\n",
            "Epoch 796: loss 0.41979\n",
            "Epoch 797: loss 0.41974\n",
            "Epoch 798: loss 0.41968\n",
            "Epoch 799: loss 0.41963\n",
            "Epoch 800: loss 0.41958\n",
            "Epoch 801: loss 0.41954\n",
            "Epoch 802: loss 0.41949\n",
            "Epoch 803: loss 0.41944\n",
            "Epoch 804: loss 0.41939\n",
            "Epoch 805: loss 0.41934\n",
            "Epoch 806: loss 0.41930\n",
            "Epoch 807: loss 0.41925\n",
            "Epoch 808: loss 0.41921\n",
            "Epoch 809: loss 0.41916\n",
            "Epoch 810: loss 0.41912\n",
            "Epoch 811: loss 0.41908\n",
            "Epoch 812: loss 0.41903\n",
            "Epoch 813: loss 0.41899\n",
            "Epoch 814: loss 0.41895\n",
            "Epoch 815: loss 0.41891\n",
            "Epoch 816: loss 0.41886\n",
            "Epoch 817: loss 0.41882\n",
            "Epoch 818: loss 0.41878\n",
            "Epoch 819: loss 0.41874\n",
            "Epoch 820: loss 0.41870\n",
            "Epoch 821: loss 0.41866\n",
            "Epoch 822: loss 0.41862\n",
            "Epoch 823: loss 0.41859\n",
            "Epoch 824: loss 0.41855\n",
            "Epoch 825: loss 0.41851\n",
            "Epoch 826: loss 0.41847\n",
            "Epoch 827: loss 0.41843\n",
            "Epoch 828: loss 0.41840\n",
            "Epoch 829: loss 0.41836\n",
            "Epoch 830: loss 0.41832\n",
            "Epoch 831: loss 0.41829\n",
            "Epoch 832: loss 0.41825\n",
            "Epoch 833: loss 0.41822\n",
            "Epoch 834: loss 0.41818\n",
            "Epoch 835: loss 0.41814\n",
            "Epoch 836: loss 0.41811\n",
            "Epoch 837: loss 0.41807\n",
            "Epoch 838: loss 0.41804\n",
            "Epoch 839: loss 0.41800\n",
            "Epoch 840: loss 0.41797\n",
            "Epoch 841: loss 0.41794\n",
            "Epoch 842: loss 0.41790\n",
            "Epoch 843: loss 0.41787\n",
            "Epoch 844: loss 0.41783\n",
            "Epoch 845: loss 0.41780\n",
            "Epoch 846: loss 0.41777\n",
            "Epoch 847: loss 0.41773\n",
            "Epoch 848: loss 0.41770\n",
            "Epoch 849: loss 0.41767\n",
            "Epoch 850: loss 0.41763\n",
            "Epoch 851: loss 0.41760\n",
            "Epoch 852: loss 0.41757\n",
            "Epoch 853: loss 0.41754\n",
            "Epoch 854: loss 0.41750\n",
            "Epoch 855: loss 0.41747\n",
            "Epoch 856: loss 0.41744\n",
            "Epoch 857: loss 0.41741\n",
            "Epoch 858: loss 0.41737\n",
            "Epoch 859: loss 0.41734\n",
            "Epoch 860: loss 0.41731\n",
            "Epoch 861: loss 0.41727\n",
            "Epoch 862: loss 0.41724\n",
            "Epoch 863: loss 0.41721\n",
            "Epoch 864: loss 0.41717\n",
            "Epoch 865: loss 0.41714\n",
            "Epoch 866: loss 0.41711\n",
            "Epoch 867: loss 0.41707\n",
            "Epoch 868: loss 0.41704\n",
            "Epoch 869: loss 0.41700\n",
            "Epoch 870: loss 0.41697\n",
            "Epoch 871: loss 0.41693\n",
            "Epoch 872: loss 0.41689\n",
            "Epoch 873: loss 0.41686\n",
            "Epoch 874: loss 0.41682\n",
            "Epoch 875: loss 0.41678\n",
            "Epoch 876: loss 0.41674\n",
            "Epoch 877: loss 0.41670\n",
            "Epoch 878: loss 0.41665\n",
            "Epoch 879: loss 0.41661\n",
            "Epoch 880: loss 0.41656\n",
            "Epoch 881: loss 0.41651\n",
            "Epoch 882: loss 0.41646\n",
            "Epoch 883: loss 0.41641\n",
            "Epoch 884: loss 0.41635\n",
            "Epoch 885: loss 0.41629\n",
            "Epoch 886: loss 0.41622\n",
            "Epoch 887: loss 0.41616\n",
            "Epoch 888: loss 0.41608\n",
            "Epoch 889: loss 0.41601\n",
            "Epoch 890: loss 0.41593\n",
            "Epoch 891: loss 0.41585\n",
            "Epoch 892: loss 0.41577\n",
            "Epoch 893: loss 0.41569\n",
            "Epoch 894: loss 0.41560\n",
            "Epoch 895: loss 0.41552\n",
            "Epoch 896: loss 0.41543\n",
            "Epoch 897: loss 0.41534\n",
            "Epoch 898: loss 0.41525\n",
            "Epoch 899: loss 0.41516\n",
            "Epoch 900: loss 0.41508\n",
            "Epoch 901: loss 0.41499\n",
            "Epoch 902: loss 0.41490\n",
            "Epoch 903: loss 0.41481\n",
            "Epoch 904: loss 0.41472\n",
            "Epoch 905: loss 0.41462\n",
            "Epoch 906: loss 0.41453\n",
            "Epoch 907: loss 0.41444\n",
            "Epoch 908: loss 0.41435\n",
            "Epoch 909: loss 0.41426\n",
            "Epoch 910: loss 0.41416\n",
            "Epoch 911: loss 0.41407\n",
            "Epoch 912: loss 0.41398\n",
            "Epoch 913: loss 0.41388\n",
            "Epoch 914: loss 0.41379\n",
            "Epoch 915: loss 0.41369\n",
            "Epoch 916: loss 0.41360\n",
            "Epoch 917: loss 0.41351\n",
            "Epoch 918: loss 0.41341\n",
            "Epoch 919: loss 0.41332\n",
            "Epoch 920: loss 0.41323\n",
            "Epoch 921: loss 0.41313\n",
            "Epoch 922: loss 0.41304\n",
            "Epoch 923: loss 0.41295\n",
            "Epoch 924: loss 0.41286\n",
            "Epoch 925: loss 0.41276\n",
            "Epoch 926: loss 0.41267\n",
            "Epoch 927: loss 0.41258\n",
            "Epoch 928: loss 0.41249\n",
            "Epoch 929: loss 0.41240\n",
            "Epoch 930: loss 0.41231\n",
            "Epoch 931: loss 0.41222\n",
            "Epoch 932: loss 0.41214\n",
            "Epoch 933: loss 0.41205\n",
            "Epoch 934: loss 0.41196\n",
            "Epoch 935: loss 0.41187\n",
            "Epoch 936: loss 0.41179\n",
            "Epoch 937: loss 0.41170\n",
            "Epoch 938: loss 0.41162\n",
            "Epoch 939: loss 0.41153\n",
            "Epoch 940: loss 0.41145\n",
            "Epoch 941: loss 0.41137\n",
            "Epoch 942: loss 0.41128\n",
            "Epoch 943: loss 0.41120\n",
            "Epoch 944: loss 0.41112\n",
            "Epoch 945: loss 0.41104\n",
            "Epoch 946: loss 0.41096\n",
            "Epoch 947: loss 0.41088\n",
            "Epoch 948: loss 0.41080\n",
            "Epoch 949: loss 0.41072\n",
            "Epoch 950: loss 0.41065\n",
            "Epoch 951: loss 0.41057\n",
            "Epoch 952: loss 0.41049\n",
            "Epoch 953: loss 0.41042\n",
            "Epoch 954: loss 0.41034\n",
            "Epoch 955: loss 0.41027\n",
            "Epoch 956: loss 0.41019\n",
            "Epoch 957: loss 0.41012\n",
            "Epoch 958: loss 0.41004\n",
            "Epoch 959: loss 0.40997\n",
            "Epoch 960: loss 0.40990\n",
            "Epoch 961: loss 0.40983\n",
            "Epoch 962: loss 0.40975\n",
            "Epoch 963: loss 0.40968\n",
            "Epoch 964: loss 0.40961\n",
            "Epoch 965: loss 0.40954\n",
            "Epoch 966: loss 0.40947\n",
            "Epoch 967: loss 0.40940\n",
            "Epoch 968: loss 0.40933\n",
            "Epoch 969: loss 0.40926\n",
            "Epoch 970: loss 0.40919\n",
            "Epoch 971: loss 0.40912\n",
            "Epoch 972: loss 0.40906\n",
            "Epoch 973: loss 0.40899\n",
            "Epoch 974: loss 0.40892\n",
            "Epoch 975: loss 0.40885\n",
            "Epoch 976: loss 0.40878\n",
            "Epoch 977: loss 0.40872\n",
            "Epoch 978: loss 0.40865\n",
            "Epoch 979: loss 0.40858\n",
            "Epoch 980: loss 0.40852\n",
            "Epoch 981: loss 0.40845\n",
            "Epoch 982: loss 0.40839\n",
            "Epoch 983: loss 0.40832\n",
            "Epoch 984: loss 0.40826\n",
            "Epoch 985: loss 0.40819\n",
            "Epoch 986: loss 0.40813\n",
            "Epoch 987: loss 0.40806\n",
            "Epoch 988: loss 0.40800\n",
            "Epoch 989: loss 0.40793\n",
            "Epoch 990: loss 0.40787\n",
            "Epoch 991: loss 0.40780\n",
            "Epoch 992: loss 0.40774\n",
            "Epoch 993: loss 0.40768\n",
            "Epoch 994: loss 0.40761\n",
            "Epoch 995: loss 0.40755\n",
            "Epoch 996: loss 0.40749\n",
            "Epoch 997: loss 0.40742\n",
            "Epoch 998: loss 0.40736\n",
            "Epoch 999: loss 0.40730\n",
            "Epoch 1000: loss 0.40723\n",
            "Epoch 1001: loss 0.40717\n",
            "Epoch 1002: loss 0.40711\n",
            "Epoch 1003: loss 0.40704\n",
            "Epoch 1004: loss 0.40698\n",
            "Epoch 1005: loss 0.40692\n",
            "Epoch 1006: loss 0.40685\n",
            "Epoch 1007: loss 0.40679\n",
            "Epoch 1008: loss 0.40673\n",
            "Epoch 1009: loss 0.40666\n",
            "Epoch 1010: loss 0.40660\n",
            "Epoch 1011: loss 0.40654\n",
            "Epoch 1012: loss 0.40647\n",
            "Epoch 1013: loss 0.40641\n",
            "Epoch 1014: loss 0.40635\n",
            "Epoch 1015: loss 0.40628\n",
            "Epoch 1016: loss 0.40622\n",
            "Epoch 1017: loss 0.40615\n",
            "Epoch 1018: loss 0.40609\n",
            "Epoch 1019: loss 0.40602\n",
            "Epoch 1020: loss 0.40596\n",
            "Epoch 1021: loss 0.40589\n",
            "Epoch 1022: loss 0.40582\n",
            "Epoch 1023: loss 0.40576\n",
            "Epoch 1024: loss 0.40569\n",
            "Epoch 1025: loss 0.40562\n",
            "Epoch 1026: loss 0.40555\n",
            "Epoch 1027: loss 0.40548\n",
            "Epoch 1028: loss 0.40541\n",
            "Epoch 1029: loss 0.40534\n",
            "Epoch 1030: loss 0.40526\n",
            "Epoch 1031: loss 0.40519\n",
            "Epoch 1032: loss 0.40512\n",
            "Epoch 1033: loss 0.40504\n",
            "Epoch 1034: loss 0.40496\n",
            "Epoch 1035: loss 0.40488\n",
            "Epoch 1036: loss 0.40480\n",
            "Epoch 1037: loss 0.40472\n",
            "Epoch 1038: loss 0.40464\n",
            "Epoch 1039: loss 0.40456\n",
            "Epoch 1040: loss 0.40448\n",
            "Epoch 1041: loss 0.40439\n",
            "Epoch 1042: loss 0.40431\n",
            "Epoch 1043: loss 0.40422\n",
            "Epoch 1044: loss 0.40414\n",
            "Epoch 1045: loss 0.40405\n",
            "Epoch 1046: loss 0.40396\n",
            "Epoch 1047: loss 0.40388\n",
            "Epoch 1048: loss 0.40379\n",
            "Epoch 1049: loss 0.40371\n",
            "Epoch 1050: loss 0.40363\n",
            "Epoch 1051: loss 0.40354\n",
            "Epoch 1052: loss 0.40346\n",
            "Epoch 1053: loss 0.40338\n",
            "Epoch 1054: loss 0.40330\n",
            "Epoch 1055: loss 0.40322\n",
            "Epoch 1056: loss 0.40315\n",
            "Epoch 1057: loss 0.40307\n",
            "Epoch 1058: loss 0.40299\n",
            "Epoch 1059: loss 0.40292\n",
            "Epoch 1060: loss 0.40285\n",
            "Epoch 1061: loss 0.40278\n",
            "Epoch 1062: loss 0.40270\n",
            "Epoch 1063: loss 0.40263\n",
            "Epoch 1064: loss 0.40256\n",
            "Epoch 1065: loss 0.40249\n",
            "Epoch 1066: loss 0.40243\n",
            "Epoch 1067: loss 0.40236\n",
            "Epoch 1068: loss 0.40229\n",
            "Epoch 1069: loss 0.40223\n",
            "Epoch 1070: loss 0.40216\n",
            "Epoch 1071: loss 0.40209\n",
            "Epoch 1072: loss 0.40203\n",
            "Epoch 1073: loss 0.40196\n",
            "Epoch 1074: loss 0.40190\n",
            "Epoch 1075: loss 0.40184\n",
            "Epoch 1076: loss 0.40177\n",
            "Epoch 1077: loss 0.40171\n",
            "Epoch 1078: loss 0.40164\n",
            "Epoch 1079: loss 0.40158\n",
            "Epoch 1080: loss 0.40152\n",
            "Epoch 1081: loss 0.40146\n",
            "Epoch 1082: loss 0.40139\n",
            "Epoch 1083: loss 0.40133\n",
            "Epoch 1084: loss 0.40127\n",
            "Epoch 1085: loss 0.40121\n",
            "Epoch 1086: loss 0.40114\n",
            "Epoch 1087: loss 0.40108\n",
            "Epoch 1088: loss 0.40102\n",
            "Epoch 1089: loss 0.40096\n",
            "Epoch 1090: loss 0.40090\n",
            "Epoch 1091: loss 0.40083\n",
            "Epoch 1092: loss 0.40077\n",
            "Epoch 1093: loss 0.40071\n",
            "Epoch 1094: loss 0.40065\n",
            "Epoch 1095: loss 0.40059\n",
            "Epoch 1096: loss 0.40053\n",
            "Epoch 1097: loss 0.40046\n",
            "Epoch 1098: loss 0.40040\n",
            "Epoch 1099: loss 0.40034\n",
            "Epoch 1100: loss 0.40028\n",
            "Epoch 1101: loss 0.40022\n",
            "Epoch 1102: loss 0.40015\n",
            "Epoch 1103: loss 0.40009\n",
            "Epoch 1104: loss 0.40003\n",
            "Epoch 1105: loss 0.39997\n",
            "Epoch 1106: loss 0.39990\n",
            "Epoch 1107: loss 0.39984\n",
            "Epoch 1108: loss 0.39978\n",
            "Epoch 1109: loss 0.39971\n",
            "Epoch 1110: loss 0.39965\n",
            "Epoch 1111: loss 0.39959\n",
            "Epoch 1112: loss 0.39952\n",
            "Epoch 1113: loss 0.39946\n",
            "Epoch 1114: loss 0.39940\n",
            "Epoch 1115: loss 0.39933\n",
            "Epoch 1116: loss 0.39927\n",
            "Epoch 1117: loss 0.39920\n",
            "Epoch 1118: loss 0.39914\n",
            "Epoch 1119: loss 0.39907\n",
            "Epoch 1120: loss 0.39901\n",
            "Epoch 1121: loss 0.39894\n",
            "Epoch 1122: loss 0.39888\n",
            "Epoch 1123: loss 0.39881\n",
            "Epoch 1124: loss 0.39875\n",
            "Epoch 1125: loss 0.39868\n",
            "Epoch 1126: loss 0.39861\n",
            "Epoch 1127: loss 0.39854\n",
            "Epoch 1128: loss 0.39848\n",
            "Epoch 1129: loss 0.39841\n",
            "Epoch 1130: loss 0.39834\n",
            "Epoch 1131: loss 0.39827\n",
            "Epoch 1132: loss 0.39821\n",
            "Epoch 1133: loss 0.39814\n",
            "Epoch 1134: loss 0.39807\n",
            "Epoch 1135: loss 0.39800\n",
            "Epoch 1136: loss 0.39793\n",
            "Epoch 1137: loss 0.39786\n",
            "Epoch 1138: loss 0.39779\n",
            "Epoch 1139: loss 0.39772\n",
            "Epoch 1140: loss 0.39764\n",
            "Epoch 1141: loss 0.39757\n",
            "Epoch 1142: loss 0.39750\n",
            "Epoch 1143: loss 0.39743\n",
            "Epoch 1144: loss 0.39736\n",
            "Epoch 1145: loss 0.39728\n",
            "Epoch 1146: loss 0.39721\n",
            "Epoch 1147: loss 0.39713\n",
            "Epoch 1148: loss 0.39706\n",
            "Epoch 1149: loss 0.39699\n",
            "Epoch 1150: loss 0.39691\n",
            "Epoch 1151: loss 0.39683\n",
            "Epoch 1152: loss 0.39676\n",
            "Epoch 1153: loss 0.39668\n",
            "Epoch 1154: loss 0.39660\n",
            "Epoch 1155: loss 0.39653\n",
            "Epoch 1156: loss 0.39645\n",
            "Epoch 1157: loss 0.39637\n",
            "Epoch 1158: loss 0.39629\n",
            "Epoch 1159: loss 0.39621\n",
            "Epoch 1160: loss 0.39613\n",
            "Epoch 1161: loss 0.39605\n",
            "Epoch 1162: loss 0.39597\n",
            "Epoch 1163: loss 0.39588\n",
            "Epoch 1164: loss 0.39580\n",
            "Epoch 1165: loss 0.39572\n",
            "Epoch 1166: loss 0.39563\n",
            "Epoch 1167: loss 0.39555\n",
            "Epoch 1168: loss 0.39546\n",
            "Epoch 1169: loss 0.39538\n",
            "Epoch 1170: loss 0.39529\n",
            "Epoch 1171: loss 0.39520\n",
            "Epoch 1172: loss 0.39511\n",
            "Epoch 1173: loss 0.39502\n",
            "Epoch 1174: loss 0.39493\n",
            "Epoch 1175: loss 0.39484\n",
            "Epoch 1176: loss 0.39475\n",
            "Epoch 1177: loss 0.39466\n",
            "Epoch 1178: loss 0.39456\n",
            "Epoch 1179: loss 0.39446\n",
            "Epoch 1180: loss 0.39437\n",
            "Epoch 1181: loss 0.39427\n",
            "Epoch 1182: loss 0.39417\n",
            "Epoch 1183: loss 0.39406\n",
            "Epoch 1184: loss 0.39396\n",
            "Epoch 1185: loss 0.39385\n",
            "Epoch 1186: loss 0.39375\n",
            "Epoch 1187: loss 0.39364\n",
            "Epoch 1188: loss 0.39353\n",
            "Epoch 1189: loss 0.39342\n",
            "Epoch 1190: loss 0.39331\n",
            "Epoch 1191: loss 0.39319\n",
            "Epoch 1192: loss 0.39308\n",
            "Epoch 1193: loss 0.39297\n",
            "Epoch 1194: loss 0.39285\n",
            "Epoch 1195: loss 0.39274\n",
            "Epoch 1196: loss 0.39263\n",
            "Epoch 1197: loss 0.39251\n",
            "Epoch 1198: loss 0.39240\n",
            "Epoch 1199: loss 0.39229\n",
            "Epoch 1200: loss 0.39218\n",
            "Epoch 1201: loss 0.39207\n",
            "Epoch 1202: loss 0.39196\n",
            "Epoch 1203: loss 0.39185\n",
            "Epoch 1204: loss 0.39174\n",
            "Epoch 1205: loss 0.39163\n",
            "Epoch 1206: loss 0.39152\n",
            "Epoch 1207: loss 0.39142\n",
            "Epoch 1208: loss 0.39131\n",
            "Epoch 1209: loss 0.39121\n",
            "Epoch 1210: loss 0.39110\n",
            "Epoch 1211: loss 0.39100\n",
            "Epoch 1212: loss 0.39089\n",
            "Epoch 1213: loss 0.39079\n",
            "Epoch 1214: loss 0.39068\n",
            "Epoch 1215: loss 0.39058\n",
            "Epoch 1216: loss 0.39048\n",
            "Epoch 1217: loss 0.39037\n",
            "Epoch 1218: loss 0.39027\n",
            "Epoch 1219: loss 0.39017\n",
            "Epoch 1220: loss 0.39007\n",
            "Epoch 1221: loss 0.38996\n",
            "Epoch 1222: loss 0.38986\n",
            "Epoch 1223: loss 0.38976\n",
            "Epoch 1224: loss 0.38966\n",
            "Epoch 1225: loss 0.38955\n",
            "Epoch 1226: loss 0.38945\n",
            "Epoch 1227: loss 0.38935\n",
            "Epoch 1228: loss 0.38925\n",
            "Epoch 1229: loss 0.38915\n",
            "Epoch 1230: loss 0.38904\n",
            "Epoch 1231: loss 0.38894\n",
            "Epoch 1232: loss 0.38884\n",
            "Epoch 1233: loss 0.38874\n",
            "Epoch 1234: loss 0.38864\n",
            "Epoch 1235: loss 0.38853\n",
            "Epoch 1236: loss 0.38843\n",
            "Epoch 1237: loss 0.38833\n",
            "Epoch 1238: loss 0.38822\n",
            "Epoch 1239: loss 0.38812\n",
            "Epoch 1240: loss 0.38802\n",
            "Epoch 1241: loss 0.38791\n",
            "Epoch 1242: loss 0.38781\n",
            "Epoch 1243: loss 0.38771\n",
            "Epoch 1244: loss 0.38760\n",
            "Epoch 1245: loss 0.38750\n",
            "Epoch 1246: loss 0.38740\n",
            "Epoch 1247: loss 0.38729\n",
            "Epoch 1248: loss 0.38719\n",
            "Epoch 1249: loss 0.38708\n",
            "Epoch 1250: loss 0.38698\n",
            "Epoch 1251: loss 0.38688\n",
            "Epoch 1252: loss 0.38677\n",
            "Epoch 1253: loss 0.38667\n",
            "Epoch 1254: loss 0.38657\n",
            "Epoch 1255: loss 0.38647\n",
            "Epoch 1256: loss 0.38637\n",
            "Epoch 1257: loss 0.38627\n",
            "Epoch 1258: loss 0.38617\n",
            "Epoch 1259: loss 0.38607\n",
            "Epoch 1260: loss 0.38597\n",
            "Epoch 1261: loss 0.38587\n",
            "Epoch 1262: loss 0.38577\n",
            "Epoch 1263: loss 0.38568\n",
            "Epoch 1264: loss 0.38558\n",
            "Epoch 1265: loss 0.38548\n",
            "Epoch 1266: loss 0.38539\n",
            "Epoch 1267: loss 0.38529\n",
            "Epoch 1268: loss 0.38520\n",
            "Epoch 1269: loss 0.38511\n",
            "Epoch 1270: loss 0.38501\n",
            "Epoch 1271: loss 0.38492\n",
            "Epoch 1272: loss 0.38483\n",
            "Epoch 1273: loss 0.38474\n",
            "Epoch 1274: loss 0.38464\n",
            "Epoch 1275: loss 0.38455\n",
            "Epoch 1276: loss 0.38446\n",
            "Epoch 1277: loss 0.38437\n",
            "Epoch 1278: loss 0.38428\n",
            "Epoch 1279: loss 0.38419\n",
            "Epoch 1280: loss 0.38410\n",
            "Epoch 1281: loss 0.38401\n",
            "Epoch 1282: loss 0.38392\n",
            "Epoch 1283: loss 0.38383\n",
            "Epoch 1284: loss 0.38373\n",
            "Epoch 1285: loss 0.38364\n",
            "Epoch 1286: loss 0.38355\n",
            "Epoch 1287: loss 0.38346\n",
            "Epoch 1288: loss 0.38337\n",
            "Epoch 1289: loss 0.38328\n",
            "Epoch 1290: loss 0.38319\n",
            "Epoch 1291: loss 0.38310\n",
            "Epoch 1292: loss 0.38300\n",
            "Epoch 1293: loss 0.38291\n",
            "Epoch 1294: loss 0.38282\n",
            "Epoch 1295: loss 0.38273\n",
            "Epoch 1296: loss 0.38264\n",
            "Epoch 1297: loss 0.38254\n",
            "Epoch 1298: loss 0.38245\n",
            "Epoch 1299: loss 0.38236\n",
            "Epoch 1300: loss 0.38226\n",
            "Epoch 1301: loss 0.38217\n",
            "Epoch 1302: loss 0.38207\n",
            "Epoch 1303: loss 0.38198\n",
            "Epoch 1304: loss 0.38188\n",
            "Epoch 1305: loss 0.38179\n",
            "Epoch 1306: loss 0.38169\n",
            "Epoch 1307: loss 0.38160\n",
            "Epoch 1308: loss 0.38150\n",
            "Epoch 1309: loss 0.38140\n",
            "Epoch 1310: loss 0.38131\n",
            "Epoch 1311: loss 0.38121\n",
            "Epoch 1312: loss 0.38111\n",
            "Epoch 1313: loss 0.38101\n",
            "Epoch 1314: loss 0.38091\n",
            "Epoch 1315: loss 0.38081\n",
            "Epoch 1316: loss 0.38071\n",
            "Epoch 1317: loss 0.38061\n",
            "Epoch 1318: loss 0.38052\n",
            "Epoch 1319: loss 0.38042\n",
            "Epoch 1320: loss 0.38032\n",
            "Epoch 1321: loss 0.38022\n",
            "Epoch 1322: loss 0.38012\n",
            "Epoch 1323: loss 0.38002\n",
            "Epoch 1324: loss 0.37992\n",
            "Epoch 1325: loss 0.37982\n",
            "Epoch 1326: loss 0.37972\n",
            "Epoch 1327: loss 0.37963\n",
            "Epoch 1328: loss 0.37953\n",
            "Epoch 1329: loss 0.37943\n",
            "Epoch 1330: loss 0.37934\n",
            "Epoch 1331: loss 0.37924\n",
            "Epoch 1332: loss 0.37915\n",
            "Epoch 1333: loss 0.37905\n",
            "Epoch 1334: loss 0.37896\n",
            "Epoch 1335: loss 0.37887\n",
            "Epoch 1336: loss 0.37877\n",
            "Epoch 1337: loss 0.37868\n",
            "Epoch 1338: loss 0.37859\n",
            "Epoch 1339: loss 0.37850\n",
            "Epoch 1340: loss 0.37841\n",
            "Epoch 1341: loss 0.37833\n",
            "Epoch 1342: loss 0.37824\n",
            "Epoch 1343: loss 0.37815\n",
            "Epoch 1344: loss 0.37807\n",
            "Epoch 1345: loss 0.37798\n",
            "Epoch 1346: loss 0.37790\n",
            "Epoch 1347: loss 0.37781\n",
            "Epoch 1348: loss 0.37773\n",
            "Epoch 1349: loss 0.37765\n",
            "Epoch 1350: loss 0.37756\n",
            "Epoch 1351: loss 0.37748\n",
            "Epoch 1352: loss 0.37740\n",
            "Epoch 1353: loss 0.37732\n",
            "Epoch 1354: loss 0.37724\n",
            "Epoch 1355: loss 0.37716\n",
            "Epoch 1356: loss 0.37709\n",
            "Epoch 1357: loss 0.37701\n",
            "Epoch 1358: loss 0.37693\n",
            "Epoch 1359: loss 0.37685\n",
            "Epoch 1360: loss 0.37678\n",
            "Epoch 1361: loss 0.37670\n",
            "Epoch 1362: loss 0.37663\n",
            "Epoch 1363: loss 0.37655\n",
            "Epoch 1364: loss 0.37648\n",
            "Epoch 1365: loss 0.37641\n",
            "Epoch 1366: loss 0.37633\n",
            "Epoch 1367: loss 0.37626\n",
            "Epoch 1368: loss 0.37619\n",
            "Epoch 1369: loss 0.37611\n",
            "Epoch 1370: loss 0.37604\n",
            "Epoch 1371: loss 0.37597\n",
            "Epoch 1372: loss 0.37590\n",
            "Epoch 1373: loss 0.37583\n",
            "Epoch 1374: loss 0.37576\n",
            "Epoch 1375: loss 0.37569\n",
            "Epoch 1376: loss 0.37562\n",
            "Epoch 1377: loss 0.37555\n",
            "Epoch 1378: loss 0.37548\n",
            "Epoch 1379: loss 0.37542\n",
            "Epoch 1380: loss 0.37535\n",
            "Epoch 1381: loss 0.37528\n",
            "Epoch 1382: loss 0.37521\n",
            "Epoch 1383: loss 0.37514\n",
            "Epoch 1384: loss 0.37508\n",
            "Epoch 1385: loss 0.37501\n",
            "Epoch 1386: loss 0.37494\n",
            "Epoch 1387: loss 0.37488\n",
            "Epoch 1388: loss 0.37481\n",
            "Epoch 1389: loss 0.37475\n",
            "Epoch 1390: loss 0.37468\n",
            "Epoch 1391: loss 0.37462\n",
            "Epoch 1392: loss 0.37455\n",
            "Epoch 1393: loss 0.37449\n",
            "Epoch 1394: loss 0.37442\n",
            "Epoch 1395: loss 0.37436\n",
            "Epoch 1396: loss 0.37429\n",
            "Epoch 1397: loss 0.37423\n",
            "Epoch 1398: loss 0.37416\n",
            "Epoch 1399: loss 0.37410\n",
            "Epoch 1400: loss 0.37404\n",
            "Epoch 1401: loss 0.37397\n",
            "Epoch 1402: loss 0.37391\n",
            "Epoch 1403: loss 0.37385\n",
            "Epoch 1404: loss 0.37378\n",
            "Epoch 1405: loss 0.37372\n",
            "Epoch 1406: loss 0.37366\n",
            "Epoch 1407: loss 0.37359\n",
            "Epoch 1408: loss 0.37353\n",
            "Epoch 1409: loss 0.37347\n",
            "Epoch 1410: loss 0.37341\n",
            "Epoch 1411: loss 0.37334\n",
            "Epoch 1412: loss 0.37328\n",
            "Epoch 1413: loss 0.37322\n",
            "Epoch 1414: loss 0.37316\n",
            "Epoch 1415: loss 0.37310\n",
            "Epoch 1416: loss 0.37303\n",
            "Epoch 1417: loss 0.37297\n",
            "Epoch 1418: loss 0.37291\n",
            "Epoch 1419: loss 0.37285\n",
            "Epoch 1420: loss 0.37279\n",
            "Epoch 1421: loss 0.37272\n",
            "Epoch 1422: loss 0.37266\n",
            "Epoch 1423: loss 0.37260\n",
            "Epoch 1424: loss 0.37254\n",
            "Epoch 1425: loss 0.37248\n",
            "Epoch 1426: loss 0.37242\n",
            "Epoch 1427: loss 0.37236\n",
            "Epoch 1428: loss 0.37229\n",
            "Epoch 1429: loss 0.37223\n",
            "Epoch 1430: loss 0.37217\n",
            "Epoch 1431: loss 0.37211\n",
            "Epoch 1432: loss 0.37205\n",
            "Epoch 1433: loss 0.37199\n",
            "Epoch 1434: loss 0.37193\n",
            "Epoch 1435: loss 0.37187\n",
            "Epoch 1436: loss 0.37181\n",
            "Epoch 1437: loss 0.37175\n",
            "Epoch 1438: loss 0.37168\n",
            "Epoch 1439: loss 0.37162\n",
            "Epoch 1440: loss 0.37156\n",
            "Epoch 1441: loss 0.37150\n",
            "Epoch 1442: loss 0.37144\n",
            "Epoch 1443: loss 0.37138\n",
            "Epoch 1444: loss 0.37132\n",
            "Epoch 1445: loss 0.37126\n",
            "Epoch 1446: loss 0.37120\n",
            "Epoch 1447: loss 0.37114\n",
            "Epoch 1448: loss 0.37108\n",
            "Epoch 1449: loss 0.37102\n",
            "Epoch 1450: loss 0.37096\n",
            "Epoch 1451: loss 0.37090\n",
            "Epoch 1452: loss 0.37084\n",
            "Epoch 1453: loss 0.37079\n",
            "Epoch 1454: loss 0.37073\n",
            "Epoch 1455: loss 0.37067\n",
            "Epoch 1456: loss 0.37061\n",
            "Epoch 1457: loss 0.37055\n",
            "Epoch 1458: loss 0.37049\n",
            "Epoch 1459: loss 0.37043\n",
            "Epoch 1460: loss 0.37037\n",
            "Epoch 1461: loss 0.37032\n",
            "Epoch 1462: loss 0.37026\n",
            "Epoch 1463: loss 0.37020\n",
            "Epoch 1464: loss 0.37014\n",
            "Epoch 1465: loss 0.37009\n",
            "Epoch 1466: loss 0.37003\n",
            "Epoch 1467: loss 0.36997\n",
            "Epoch 1468: loss 0.36991\n",
            "Epoch 1469: loss 0.36986\n",
            "Epoch 1470: loss 0.36980\n",
            "Epoch 1471: loss 0.36974\n",
            "Epoch 1472: loss 0.36969\n",
            "Epoch 1473: loss 0.36963\n",
            "Epoch 1474: loss 0.36958\n",
            "Epoch 1475: loss 0.36952\n",
            "Epoch 1476: loss 0.36946\n",
            "Epoch 1477: loss 0.36941\n",
            "Epoch 1478: loss 0.36935\n",
            "Epoch 1479: loss 0.36930\n",
            "Epoch 1480: loss 0.36924\n",
            "Epoch 1481: loss 0.36919\n",
            "Epoch 1482: loss 0.36913\n",
            "Epoch 1483: loss 0.36908\n",
            "Epoch 1484: loss 0.36903\n",
            "Epoch 1485: loss 0.36897\n",
            "Epoch 1486: loss 0.36892\n",
            "Epoch 1487: loss 0.36886\n",
            "Epoch 1488: loss 0.36881\n",
            "Epoch 1489: loss 0.36876\n",
            "Epoch 1490: loss 0.36870\n",
            "Epoch 1491: loss 0.36865\n",
            "Epoch 1492: loss 0.36860\n",
            "Epoch 1493: loss 0.36855\n",
            "Epoch 1494: loss 0.36849\n",
            "Epoch 1495: loss 0.36844\n",
            "Epoch 1496: loss 0.36839\n",
            "Epoch 1497: loss 0.36834\n",
            "Epoch 1498: loss 0.36829\n",
            "Epoch 1499: loss 0.36823\n",
            "Epoch 1500: loss 0.36818\n",
            "Epoch 1501: loss 0.36813\n",
            "Epoch 1502: loss 0.36808\n",
            "Epoch 1503: loss 0.36803\n",
            "Epoch 1504: loss 0.36798\n",
            "Epoch 1505: loss 0.36793\n",
            "Epoch 1506: loss 0.36788\n",
            "Epoch 1507: loss 0.36783\n",
            "Epoch 1508: loss 0.36778\n",
            "Epoch 1509: loss 0.36773\n",
            "Epoch 1510: loss 0.36768\n",
            "Epoch 1511: loss 0.36763\n",
            "Epoch 1512: loss 0.36758\n",
            "Epoch 1513: loss 0.36753\n",
            "Epoch 1514: loss 0.36748\n",
            "Epoch 1515: loss 0.36743\n",
            "Epoch 1516: loss 0.36738\n",
            "Epoch 1517: loss 0.36733\n",
            "Epoch 1518: loss 0.36728\n",
            "Epoch 1519: loss 0.36723\n",
            "Epoch 1520: loss 0.36719\n",
            "Epoch 1521: loss 0.36714\n",
            "Epoch 1522: loss 0.36709\n",
            "Epoch 1523: loss 0.36704\n",
            "Epoch 1524: loss 0.36699\n",
            "Epoch 1525: loss 0.36694\n",
            "Epoch 1526: loss 0.36690\n",
            "Epoch 1527: loss 0.36685\n",
            "Epoch 1528: loss 0.36680\n",
            "Epoch 1529: loss 0.36675\n",
            "Epoch 1530: loss 0.36671\n",
            "Epoch 1531: loss 0.36666\n",
            "Epoch 1532: loss 0.36661\n",
            "Epoch 1533: loss 0.36657\n",
            "Epoch 1534: loss 0.36652\n",
            "Epoch 1535: loss 0.36647\n",
            "Epoch 1536: loss 0.36643\n",
            "Epoch 1537: loss 0.36638\n",
            "Epoch 1538: loss 0.36633\n",
            "Epoch 1539: loss 0.36629\n",
            "Epoch 1540: loss 0.36624\n",
            "Epoch 1541: loss 0.36620\n",
            "Epoch 1542: loss 0.36615\n",
            "Epoch 1543: loss 0.36610\n",
            "Epoch 1544: loss 0.36606\n",
            "Epoch 1545: loss 0.36601\n",
            "Epoch 1546: loss 0.36597\n",
            "Epoch 1547: loss 0.36592\n",
            "Epoch 1548: loss 0.36588\n",
            "Epoch 1549: loss 0.36583\n",
            "Epoch 1550: loss 0.36579\n",
            "Epoch 1551: loss 0.36574\n",
            "Epoch 1552: loss 0.36570\n",
            "Epoch 1553: loss 0.36565\n",
            "Epoch 1554: loss 0.36561\n",
            "Epoch 1555: loss 0.36556\n",
            "Epoch 1556: loss 0.36552\n",
            "Epoch 1557: loss 0.36547\n",
            "Epoch 1558: loss 0.36543\n",
            "Epoch 1559: loss 0.36539\n",
            "Epoch 1560: loss 0.36534\n",
            "Epoch 1561: loss 0.36530\n",
            "Epoch 1562: loss 0.36525\n",
            "Epoch 1563: loss 0.36521\n",
            "Epoch 1564: loss 0.36517\n",
            "Epoch 1565: loss 0.36512\n",
            "Epoch 1566: loss 0.36508\n",
            "Epoch 1567: loss 0.36503\n",
            "Epoch 1568: loss 0.36499\n",
            "Epoch 1569: loss 0.36495\n",
            "Epoch 1570: loss 0.36490\n",
            "Epoch 1571: loss 0.36486\n",
            "Epoch 1572: loss 0.36482\n",
            "Epoch 1573: loss 0.36478\n",
            "Epoch 1574: loss 0.36473\n",
            "Epoch 1575: loss 0.36469\n",
            "Epoch 1576: loss 0.36465\n",
            "Epoch 1577: loss 0.36460\n",
            "Epoch 1578: loss 0.36456\n",
            "Epoch 1579: loss 0.36452\n",
            "Epoch 1580: loss 0.36448\n",
            "Epoch 1581: loss 0.36443\n",
            "Epoch 1582: loss 0.36439\n",
            "Epoch 1583: loss 0.36435\n",
            "Epoch 1584: loss 0.36431\n",
            "Epoch 1585: loss 0.36427\n",
            "Epoch 1586: loss 0.36422\n",
            "Epoch 1587: loss 0.36418\n",
            "Epoch 1588: loss 0.36414\n",
            "Epoch 1589: loss 0.36410\n",
            "Epoch 1590: loss 0.36406\n",
            "Epoch 1591: loss 0.36401\n",
            "Epoch 1592: loss 0.36397\n",
            "Epoch 1593: loss 0.36393\n",
            "Epoch 1594: loss 0.36389\n",
            "Epoch 1595: loss 0.36385\n",
            "Epoch 1596: loss 0.36381\n",
            "Epoch 1597: loss 0.36376\n",
            "Epoch 1598: loss 0.36372\n",
            "Epoch 1599: loss 0.36368\n",
            "Epoch 1600: loss 0.36364\n",
            "Epoch 1601: loss 0.36360\n",
            "Epoch 1602: loss 0.36356\n",
            "Epoch 1603: loss 0.36352\n",
            "Epoch 1604: loss 0.36348\n",
            "Epoch 1605: loss 0.36343\n",
            "Epoch 1606: loss 0.36339\n",
            "Epoch 1607: loss 0.36335\n",
            "Epoch 1608: loss 0.36331\n",
            "Epoch 1609: loss 0.36327\n",
            "Epoch 1610: loss 0.36323\n",
            "Epoch 1611: loss 0.36319\n",
            "Epoch 1612: loss 0.36315\n",
            "Epoch 1613: loss 0.36310\n",
            "Epoch 1614: loss 0.36306\n",
            "Epoch 1615: loss 0.36302\n",
            "Epoch 1616: loss 0.36298\n",
            "Epoch 1617: loss 0.36294\n",
            "Epoch 1618: loss 0.36290\n",
            "Epoch 1619: loss 0.36286\n",
            "Epoch 1620: loss 0.36281\n",
            "Epoch 1621: loss 0.36277\n",
            "Epoch 1622: loss 0.36273\n",
            "Epoch 1623: loss 0.36269\n",
            "Epoch 1624: loss 0.36265\n",
            "Epoch 1625: loss 0.36260\n",
            "Epoch 1626: loss 0.36256\n",
            "Epoch 1627: loss 0.36252\n",
            "Epoch 1628: loss 0.36248\n",
            "Epoch 1629: loss 0.36243\n",
            "Epoch 1630: loss 0.36239\n",
            "Epoch 1631: loss 0.36235\n",
            "Epoch 1632: loss 0.36231\n",
            "Epoch 1633: loss 0.36226\n",
            "Epoch 1634: loss 0.36222\n",
            "Epoch 1635: loss 0.36218\n",
            "Epoch 1636: loss 0.36213\n",
            "Epoch 1637: loss 0.36209\n",
            "Epoch 1638: loss 0.36204\n",
            "Epoch 1639: loss 0.36200\n",
            "Epoch 1640: loss 0.36195\n",
            "Epoch 1641: loss 0.36191\n",
            "Epoch 1642: loss 0.36186\n",
            "Epoch 1643: loss 0.36182\n",
            "Epoch 1644: loss 0.36177\n",
            "Epoch 1645: loss 0.36172\n",
            "Epoch 1646: loss 0.36168\n",
            "Epoch 1647: loss 0.36163\n",
            "Epoch 1648: loss 0.36158\n",
            "Epoch 1649: loss 0.36153\n",
            "Epoch 1650: loss 0.36148\n",
            "Epoch 1651: loss 0.36143\n",
            "Epoch 1652: loss 0.36138\n",
            "Epoch 1653: loss 0.36133\n",
            "Epoch 1654: loss 0.36128\n",
            "Epoch 1655: loss 0.36123\n",
            "Epoch 1656: loss 0.36117\n",
            "Epoch 1657: loss 0.36112\n",
            "Epoch 1658: loss 0.36106\n",
            "Epoch 1659: loss 0.36101\n",
            "Epoch 1660: loss 0.36095\n",
            "Epoch 1661: loss 0.36090\n",
            "Epoch 1662: loss 0.36084\n",
            "Epoch 1663: loss 0.36078\n",
            "Epoch 1664: loss 0.36072\n",
            "Epoch 1665: loss 0.36066\n",
            "Epoch 1666: loss 0.36060\n",
            "Epoch 1667: loss 0.36054\n",
            "Epoch 1668: loss 0.36048\n",
            "Epoch 1669: loss 0.36042\n",
            "Epoch 1670: loss 0.36036\n",
            "Epoch 1671: loss 0.36030\n",
            "Epoch 1672: loss 0.36023\n",
            "Epoch 1673: loss 0.36017\n",
            "Epoch 1674: loss 0.36011\n",
            "Epoch 1675: loss 0.36004\n",
            "Epoch 1676: loss 0.35998\n",
            "Epoch 1677: loss 0.35991\n",
            "Epoch 1678: loss 0.35985\n",
            "Epoch 1679: loss 0.35979\n",
            "Epoch 1680: loss 0.35972\n",
            "Epoch 1681: loss 0.35966\n",
            "Epoch 1682: loss 0.35960\n",
            "Epoch 1683: loss 0.35953\n",
            "Epoch 1684: loss 0.35947\n",
            "Epoch 1685: loss 0.35941\n",
            "Epoch 1686: loss 0.35935\n",
            "Epoch 1687: loss 0.35929\n",
            "Epoch 1688: loss 0.35922\n",
            "Epoch 1689: loss 0.35916\n",
            "Epoch 1690: loss 0.35910\n",
            "Epoch 1691: loss 0.35904\n",
            "Epoch 1692: loss 0.35898\n",
            "Epoch 1693: loss 0.35892\n",
            "Epoch 1694: loss 0.35886\n",
            "Epoch 1695: loss 0.35880\n",
            "Epoch 1696: loss 0.35874\n",
            "Epoch 1697: loss 0.35868\n",
            "Epoch 1698: loss 0.35862\n",
            "Epoch 1699: loss 0.35856\n",
            "Epoch 1700: loss 0.35850\n",
            "Epoch 1701: loss 0.35844\n",
            "Epoch 1702: loss 0.35838\n",
            "Epoch 1703: loss 0.35832\n",
            "Epoch 1704: loss 0.35826\n",
            "Epoch 1705: loss 0.35820\n",
            "Epoch 1706: loss 0.35814\n",
            "Epoch 1707: loss 0.35808\n",
            "Epoch 1708: loss 0.35802\n",
            "Epoch 1709: loss 0.35796\n",
            "Epoch 1710: loss 0.35790\n",
            "Epoch 1711: loss 0.35784\n",
            "Epoch 1712: loss 0.35778\n",
            "Epoch 1713: loss 0.35772\n",
            "Epoch 1714: loss 0.35766\n",
            "Epoch 1715: loss 0.35760\n",
            "Epoch 1716: loss 0.35754\n",
            "Epoch 1717: loss 0.35747\n",
            "Epoch 1718: loss 0.35741\n",
            "Epoch 1719: loss 0.35735\n",
            "Epoch 1720: loss 0.35729\n",
            "Epoch 1721: loss 0.35723\n",
            "Epoch 1722: loss 0.35716\n",
            "Epoch 1723: loss 0.35710\n",
            "Epoch 1724: loss 0.35703\n",
            "Epoch 1725: loss 0.35697\n",
            "Epoch 1726: loss 0.35690\n",
            "Epoch 1727: loss 0.35684\n",
            "Epoch 1728: loss 0.35677\n",
            "Epoch 1729: loss 0.35670\n",
            "Epoch 1730: loss 0.35663\n",
            "Epoch 1731: loss 0.35657\n",
            "Epoch 1732: loss 0.35650\n",
            "Epoch 1733: loss 0.35643\n",
            "Epoch 1734: loss 0.35635\n",
            "Epoch 1735: loss 0.35628\n",
            "Epoch 1736: loss 0.35621\n",
            "Epoch 1737: loss 0.35614\n",
            "Epoch 1738: loss 0.35607\n",
            "Epoch 1739: loss 0.35600\n",
            "Epoch 1740: loss 0.35592\n",
            "Epoch 1741: loss 0.35585\n",
            "Epoch 1742: loss 0.35578\n",
            "Epoch 1743: loss 0.35571\n",
            "Epoch 1744: loss 0.35564\n",
            "Epoch 1745: loss 0.35557\n",
            "Epoch 1746: loss 0.35550\n",
            "Epoch 1747: loss 0.35543\n",
            "Epoch 1748: loss 0.35536\n",
            "Epoch 1749: loss 0.35529\n",
            "Epoch 1750: loss 0.35522\n",
            "Epoch 1751: loss 0.35516\n",
            "Epoch 1752: loss 0.35509\n",
            "Epoch 1753: loss 0.35502\n",
            "Epoch 1754: loss 0.35496\n",
            "Epoch 1755: loss 0.35489\n",
            "Epoch 1756: loss 0.35483\n",
            "Epoch 1757: loss 0.35477\n",
            "Epoch 1758: loss 0.35470\n",
            "Epoch 1759: loss 0.35464\n",
            "Epoch 1760: loss 0.35458\n",
            "Epoch 1761: loss 0.35452\n",
            "Epoch 1762: loss 0.35446\n",
            "Epoch 1763: loss 0.35440\n",
            "Epoch 1764: loss 0.35434\n",
            "Epoch 1765: loss 0.35428\n",
            "Epoch 1766: loss 0.35422\n",
            "Epoch 1767: loss 0.35417\n",
            "Epoch 1768: loss 0.35411\n",
            "Epoch 1769: loss 0.35405\n",
            "Epoch 1770: loss 0.35399\n",
            "Epoch 1771: loss 0.35394\n",
            "Epoch 1772: loss 0.35388\n",
            "Epoch 1773: loss 0.35383\n",
            "Epoch 1774: loss 0.35377\n",
            "Epoch 1775: loss 0.35372\n",
            "Epoch 1776: loss 0.35366\n",
            "Epoch 1777: loss 0.35361\n",
            "Epoch 1778: loss 0.35355\n",
            "Epoch 1779: loss 0.35350\n",
            "Epoch 1780: loss 0.35344\n",
            "Epoch 1781: loss 0.35339\n",
            "Epoch 1782: loss 0.35334\n",
            "Epoch 1783: loss 0.35328\n",
            "Epoch 1784: loss 0.35323\n",
            "Epoch 1785: loss 0.35318\n",
            "Epoch 1786: loss 0.35312\n",
            "Epoch 1787: loss 0.35307\n",
            "Epoch 1788: loss 0.35302\n",
            "Epoch 1789: loss 0.35297\n",
            "Epoch 1790: loss 0.35291\n",
            "Epoch 1791: loss 0.35286\n",
            "Epoch 1792: loss 0.35281\n",
            "Epoch 1793: loss 0.35276\n",
            "Epoch 1794: loss 0.35270\n",
            "Epoch 1795: loss 0.35265\n",
            "Epoch 1796: loss 0.35260\n",
            "Epoch 1797: loss 0.35255\n",
            "Epoch 1798: loss 0.35249\n",
            "Epoch 1799: loss 0.35244\n",
            "Epoch 1800: loss 0.35239\n",
            "Epoch 1801: loss 0.35234\n",
            "Epoch 1802: loss 0.35228\n",
            "Epoch 1803: loss 0.35223\n",
            "Epoch 1804: loss 0.35218\n",
            "Epoch 1805: loss 0.35213\n",
            "Epoch 1806: loss 0.35208\n",
            "Epoch 1807: loss 0.35202\n",
            "Epoch 1808: loss 0.35197\n",
            "Epoch 1809: loss 0.35192\n",
            "Epoch 1810: loss 0.35187\n",
            "Epoch 1811: loss 0.35181\n",
            "Epoch 1812: loss 0.35176\n",
            "Epoch 1813: loss 0.35171\n",
            "Epoch 1814: loss 0.35166\n",
            "Epoch 1815: loss 0.35160\n",
            "Epoch 1816: loss 0.35155\n",
            "Epoch 1817: loss 0.35150\n",
            "Epoch 1818: loss 0.35145\n",
            "Epoch 1819: loss 0.35139\n",
            "Epoch 1820: loss 0.35134\n",
            "Epoch 1821: loss 0.35129\n",
            "Epoch 1822: loss 0.35124\n",
            "Epoch 1823: loss 0.35118\n",
            "Epoch 1824: loss 0.35113\n",
            "Epoch 1825: loss 0.35108\n",
            "Epoch 1826: loss 0.35103\n",
            "Epoch 1827: loss 0.35097\n",
            "Epoch 1828: loss 0.35092\n",
            "Epoch 1829: loss 0.35087\n",
            "Epoch 1830: loss 0.35081\n",
            "Epoch 1831: loss 0.35076\n",
            "Epoch 1832: loss 0.35071\n",
            "Epoch 1833: loss 0.35066\n",
            "Epoch 1834: loss 0.35060\n",
            "Epoch 1835: loss 0.35055\n",
            "Epoch 1836: loss 0.35050\n",
            "Epoch 1837: loss 0.35045\n",
            "Epoch 1838: loss 0.35040\n",
            "Epoch 1839: loss 0.35034\n",
            "Epoch 1840: loss 0.35029\n",
            "Epoch 1841: loss 0.35024\n",
            "Epoch 1842: loss 0.35019\n",
            "Epoch 1843: loss 0.35013\n",
            "Epoch 1844: loss 0.35008\n",
            "Epoch 1845: loss 0.35003\n",
            "Epoch 1846: loss 0.34998\n",
            "Epoch 1847: loss 0.34993\n",
            "Epoch 1848: loss 0.34988\n",
            "Epoch 1849: loss 0.34982\n",
            "Epoch 1850: loss 0.34977\n",
            "Epoch 1851: loss 0.34972\n",
            "Epoch 1852: loss 0.34967\n",
            "Epoch 1853: loss 0.34962\n",
            "Epoch 1854: loss 0.34957\n",
            "Epoch 1855: loss 0.34952\n",
            "Epoch 1856: loss 0.34947\n",
            "Epoch 1857: loss 0.34941\n",
            "Epoch 1858: loss 0.34936\n",
            "Epoch 1859: loss 0.34931\n",
            "Epoch 1860: loss 0.34926\n",
            "Epoch 1861: loss 0.34921\n",
            "Epoch 1862: loss 0.34916\n",
            "Epoch 1863: loss 0.34911\n",
            "Epoch 1864: loss 0.34906\n",
            "Epoch 1865: loss 0.34901\n",
            "Epoch 1866: loss 0.34896\n",
            "Epoch 1867: loss 0.34891\n",
            "Epoch 1868: loss 0.34886\n",
            "Epoch 1869: loss 0.34881\n",
            "Epoch 1870: loss 0.34876\n",
            "Epoch 1871: loss 0.34871\n",
            "Epoch 1872: loss 0.34867\n",
            "Epoch 1873: loss 0.34862\n",
            "Epoch 1874: loss 0.34857\n",
            "Epoch 1875: loss 0.34852\n",
            "Epoch 1876: loss 0.34847\n",
            "Epoch 1877: loss 0.34842\n",
            "Epoch 1878: loss 0.34837\n",
            "Epoch 1879: loss 0.34832\n",
            "Epoch 1880: loss 0.34828\n",
            "Epoch 1881: loss 0.34823\n",
            "Epoch 1882: loss 0.34818\n",
            "Epoch 1883: loss 0.34813\n",
            "Epoch 1884: loss 0.34809\n",
            "Epoch 1885: loss 0.34804\n",
            "Epoch 1886: loss 0.34799\n",
            "Epoch 1887: loss 0.34794\n",
            "Epoch 1888: loss 0.34790\n",
            "Epoch 1889: loss 0.34785\n",
            "Epoch 1890: loss 0.34780\n",
            "Epoch 1891: loss 0.34776\n",
            "Epoch 1892: loss 0.34771\n",
            "Epoch 1893: loss 0.34766\n",
            "Epoch 1894: loss 0.34762\n",
            "Epoch 1895: loss 0.34757\n",
            "Epoch 1896: loss 0.34753\n",
            "Epoch 1897: loss 0.34748\n",
            "Epoch 1898: loss 0.34744\n",
            "Epoch 1899: loss 0.34739\n",
            "Epoch 1900: loss 0.34734\n",
            "Epoch 1901: loss 0.34730\n",
            "Epoch 1902: loss 0.34725\n",
            "Epoch 1903: loss 0.34721\n",
            "Epoch 1904: loss 0.34716\n",
            "Epoch 1905: loss 0.34712\n",
            "Epoch 1906: loss 0.34708\n",
            "Epoch 1907: loss 0.34703\n",
            "Epoch 1908: loss 0.34699\n",
            "Epoch 1909: loss 0.34694\n",
            "Epoch 1910: loss 0.34690\n",
            "Epoch 1911: loss 0.34686\n",
            "Epoch 1912: loss 0.34681\n",
            "Epoch 1913: loss 0.34677\n",
            "Epoch 1914: loss 0.34673\n",
            "Epoch 1915: loss 0.34668\n",
            "Epoch 1916: loss 0.34664\n",
            "Epoch 1917: loss 0.34660\n",
            "Epoch 1918: loss 0.34655\n",
            "Epoch 1919: loss 0.34651\n",
            "Epoch 1920: loss 0.34647\n",
            "Epoch 1921: loss 0.34643\n",
            "Epoch 1922: loss 0.34638\n",
            "Epoch 1923: loss 0.34634\n",
            "Epoch 1924: loss 0.34630\n",
            "Epoch 1925: loss 0.34626\n",
            "Epoch 1926: loss 0.34622\n",
            "Epoch 1927: loss 0.34618\n",
            "Epoch 1928: loss 0.34613\n",
            "Epoch 1929: loss 0.34609\n",
            "Epoch 1930: loss 0.34605\n",
            "Epoch 1931: loss 0.34601\n",
            "Epoch 1932: loss 0.34597\n",
            "Epoch 1933: loss 0.34593\n",
            "Epoch 1934: loss 0.34589\n",
            "Epoch 1935: loss 0.34585\n",
            "Epoch 1936: loss 0.34581\n",
            "Epoch 1937: loss 0.34577\n",
            "Epoch 1938: loss 0.34573\n",
            "Epoch 1939: loss 0.34569\n",
            "Epoch 1940: loss 0.34565\n",
            "Epoch 1941: loss 0.34561\n",
            "Epoch 1942: loss 0.34557\n",
            "Epoch 1943: loss 0.34553\n",
            "Epoch 1944: loss 0.34549\n",
            "Epoch 1945: loss 0.34545\n",
            "Epoch 1946: loss 0.34541\n",
            "Epoch 1947: loss 0.34537\n",
            "Epoch 1948: loss 0.34533\n",
            "Epoch 1949: loss 0.34529\n",
            "Epoch 1950: loss 0.34526\n",
            "Epoch 1951: loss 0.34522\n",
            "Epoch 1952: loss 0.34518\n",
            "Epoch 1953: loss 0.34514\n",
            "Epoch 1954: loss 0.34510\n",
            "Epoch 1955: loss 0.34506\n",
            "Epoch 1956: loss 0.34503\n",
            "Epoch 1957: loss 0.34499\n",
            "Epoch 1958: loss 0.34495\n",
            "Epoch 1959: loss 0.34491\n",
            "Epoch 1960: loss 0.34488\n",
            "Epoch 1961: loss 0.34484\n",
            "Epoch 1962: loss 0.34480\n",
            "Epoch 1963: loss 0.34476\n",
            "Epoch 1964: loss 0.34473\n",
            "Epoch 1965: loss 0.34469\n",
            "Epoch 1966: loss 0.34465\n",
            "Epoch 1967: loss 0.34462\n",
            "Epoch 1968: loss 0.34458\n",
            "Epoch 1969: loss 0.34454\n",
            "Epoch 1970: loss 0.34451\n",
            "Epoch 1971: loss 0.34447\n",
            "Epoch 1972: loss 0.34443\n",
            "Epoch 1973: loss 0.34440\n",
            "Epoch 1974: loss 0.34436\n",
            "Epoch 1975: loss 0.34433\n",
            "Epoch 1976: loss 0.34429\n",
            "Epoch 1977: loss 0.34425\n",
            "Epoch 1978: loss 0.34422\n",
            "Epoch 1979: loss 0.34418\n",
            "Epoch 1980: loss 0.34415\n",
            "Epoch 1981: loss 0.34411\n",
            "Epoch 1982: loss 0.34408\n",
            "Epoch 1983: loss 0.34404\n",
            "Epoch 1984: loss 0.34401\n",
            "Epoch 1985: loss 0.34397\n",
            "Epoch 1986: loss 0.34394\n",
            "Epoch 1987: loss 0.34390\n",
            "Epoch 1988: loss 0.34387\n",
            "Epoch 1989: loss 0.34383\n",
            "Epoch 1990: loss 0.34380\n",
            "Epoch 1991: loss 0.34376\n",
            "Epoch 1992: loss 0.34373\n",
            "Epoch 1993: loss 0.34369\n",
            "Epoch 1994: loss 0.34366\n",
            "Epoch 1995: loss 0.34363\n",
            "Epoch 1996: loss 0.34359\n",
            "Epoch 1997: loss 0.34356\n",
            "Epoch 1998: loss 0.34352\n",
            "Epoch 1999: loss 0.34349\n",
            "Epoch 2000: loss 0.34346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyTjLzELSdQF"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZafmlssFs5SG",
        "outputId": "a2c80c72-d616-427e-a9b4-564f8904ab64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "network.eval()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=8, out_features=5, bias=True)\n",
              "  (1): Sigmoid()\n",
              "  (2): Linear(in_features=5, out_features=5, bias=True)\n",
              "  (3): Sigmoid()\n",
              "  (4): Linear(in_features=5, out_features=1, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuL49MUEtOrh"
      },
      "source": [
        "X_test = torch.tensor(X_test, dtype=torch.float)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe8muTxbtc1G"
      },
      "source": [
        "predictions = network.forward(X_test)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn0leHiAtqpx",
        "outputId": "f00e1fe1-5262-4f63-cf4c-65bd10f9adb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.1369e-01],\n",
              "        [2.5028e-01],\n",
              "        [5.3634e-01],\n",
              "        [5.0925e-09],\n",
              "        [9.8598e-01],\n",
              "        [4.0122e-01],\n",
              "        [8.8442e-01],\n",
              "        [9.8808e-01],\n",
              "        [3.4753e-11],\n",
              "        [6.3060e-09],\n",
              "        [1.4608e-02],\n",
              "        [1.2662e-01],\n",
              "        [9.5125e-03],\n",
              "        [4.4396e-08],\n",
              "        [1.5916e-12],\n",
              "        [8.5030e-01],\n",
              "        [1.0638e-01],\n",
              "        [1.1214e-01],\n",
              "        [2.5317e-01],\n",
              "        [5.1227e-01],\n",
              "        [1.3426e-05],\n",
              "        [2.9952e-01],\n",
              "        [1.8163e-06],\n",
              "        [3.7404e-01],\n",
              "        [9.9967e-01],\n",
              "        [1.1437e-09],\n",
              "        [1.3392e-08],\n",
              "        [9.7609e-10],\n",
              "        [7.7915e-01],\n",
              "        [5.8739e-03],\n",
              "        [4.6114e-01],\n",
              "        [9.1269e-01],\n",
              "        [2.4174e-02],\n",
              "        [5.2128e-01],\n",
              "        [3.4926e-01],\n",
              "        [1.8377e-02],\n",
              "        [9.0878e-01],\n",
              "        [8.4739e-01],\n",
              "        [1.2232e-04],\n",
              "        [1.0988e-01],\n",
              "        [5.4782e-08],\n",
              "        [8.1368e-01],\n",
              "        [1.0600e-01],\n",
              "        [7.0715e-02],\n",
              "        [6.9196e-04],\n",
              "        [3.5783e-01],\n",
              "        [1.8039e-01],\n",
              "        [7.7715e-01],\n",
              "        [7.7272e-01],\n",
              "        [1.1786e-02],\n",
              "        [5.0966e-01],\n",
              "        [7.4135e-02],\n",
              "        [1.6910e-07],\n",
              "        [5.9416e-01],\n",
              "        [1.5041e-01],\n",
              "        [2.1913e-09],\n",
              "        [8.8265e-01],\n",
              "        [3.5413e-01],\n",
              "        [3.3337e-01],\n",
              "        [5.6957e-02],\n",
              "        [4.4283e-01],\n",
              "        [1.6109e-01],\n",
              "        [9.9686e-01],\n",
              "        [6.1336e-01],\n",
              "        [7.9450e-10],\n",
              "        [2.6901e-01],\n",
              "        [4.2997e-02],\n",
              "        [1.8792e-01],\n",
              "        [1.5986e-01],\n",
              "        [4.7317e-08],\n",
              "        [6.9213e-02],\n",
              "        [6.9037e-01],\n",
              "        [5.4798e-01],\n",
              "        [4.4472e-09],\n",
              "        [7.4244e-02],\n",
              "        [6.4503e-01],\n",
              "        [9.6046e-11],\n",
              "        [7.0811e-01],\n",
              "        [3.9058e-01],\n",
              "        [3.0082e-02],\n",
              "        [2.5439e-05],\n",
              "        [3.3267e-01],\n",
              "        [7.6880e-03],\n",
              "        [5.0042e-01],\n",
              "        [5.3687e-01],\n",
              "        [4.8233e-02],\n",
              "        [1.1489e-01],\n",
              "        [4.0879e-09],\n",
              "        [2.6302e-02],\n",
              "        [2.0943e-01],\n",
              "        [4.3694e-01],\n",
              "        [1.7248e-12],\n",
              "        [2.3110e-01],\n",
              "        [2.2081e-01],\n",
              "        [7.6468e-09],\n",
              "        [1.8438e-01],\n",
              "        [1.5831e-01],\n",
              "        [1.8768e-05],\n",
              "        [5.4740e-01],\n",
              "        [9.0076e-03],\n",
              "        [2.2364e-08],\n",
              "        [1.8869e-06],\n",
              "        [1.2251e-05],\n",
              "        [7.3211e-01],\n",
              "        [3.7235e-08],\n",
              "        [9.3018e-01],\n",
              "        [8.4002e-01],\n",
              "        [9.7534e-02],\n",
              "        [3.9140e-03],\n",
              "        [4.7279e-02],\n",
              "        [4.7660e-01],\n",
              "        [1.7751e-02],\n",
              "        [3.2031e-08],\n",
              "        [1.8327e-02],\n",
              "        [1.5719e-01],\n",
              "        [4.8938e-01],\n",
              "        [4.5646e-01],\n",
              "        [1.1390e-01],\n",
              "        [9.9952e-01],\n",
              "        [2.6774e-09],\n",
              "        [7.6617e-01],\n",
              "        [1.5553e-01],\n",
              "        [2.8175e-02],\n",
              "        [1.7971e-01],\n",
              "        [5.0682e-08],\n",
              "        [1.1601e-01],\n",
              "        [1.5218e-01],\n",
              "        [1.3011e-02],\n",
              "        [3.9929e-01],\n",
              "        [2.7914e-01],\n",
              "        [3.4478e-02],\n",
              "        [1.2205e-04],\n",
              "        [6.7638e-01],\n",
              "        [2.8277e-07],\n",
              "        [7.5090e-01],\n",
              "        [3.2189e-01],\n",
              "        [1.7212e-01],\n",
              "        [8.6209e-01],\n",
              "        [9.8946e-01],\n",
              "        [2.7012e-01],\n",
              "        [7.3387e-13],\n",
              "        [5.1065e-01],\n",
              "        [3.0479e-01],\n",
              "        [1.7594e-01],\n",
              "        [1.3042e-03],\n",
              "        [1.7132e-01],\n",
              "        [1.1145e-02],\n",
              "        [3.0069e-01],\n",
              "        [3.9249e-01],\n",
              "        [3.3229e-01],\n",
              "        [9.3619e-01],\n",
              "        [4.3149e-08],\n",
              "        [9.2985e-01],\n",
              "        [6.2382e-10]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu8CV7XawV_K",
        "outputId": "6c2d5c8d-1402-4c16-ad28-d672f70b24fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predictions = (predictions >= 0.5)\n",
        "predictions"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False],\n",
              "        [ True],\n",
              "        [False]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVPFTbGeuSU5",
        "outputId": "c74c3d27-8d62-433b-9398-6dbea4417084",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_test"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
              "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7jfnFtZuNVn",
        "outputId": "a7be3e8d-9690-430e-cce9-6f116d0ae941",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "accuracy_score(y_test, predictions.detach().numpy())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7662337662337663"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYLq3Y7ctnbS",
        "outputId": "91d8d87e-edad-46ee-d841-34a86408d531",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cm = confusion_matrix(y_test, predictions.detach().numpy())\n",
        "cm"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[93, 14],\n",
              "       [22, 25]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3C7dimytqG6",
        "outputId": "8e07b70c-b491-4c6a-aae8-d1d397db4d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1471f5c550>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUQUlEQVR4nO3df5RVZb3H8fdXkETspiCMIJWWaGku7Wamy7SSTEtNupbX8hbXuE0/Le2XZKXZD8uWmV6X1Z00Hc1fXIyg7sqiyV9ZkVj+QMlQgoQQjCQLLZ2Z7/1jDjQJzJ6Rs885bN4v1rPmnL3Peeari/VZD89+9rMjM5EklWebZhcgSVVn0EpSyQxaSSqZQStJJTNoJalkw8v+BU/9cbHLGrSBkRMObXYJakHdTy6Pze1jKJmz7c4v2OzfNxiOaCWpZKWPaCWpoXp7ml3BBgxaSdXS093sCjZg0EqqlMzeZpewAedoJVVLb+/gW4GI+FBELIiIeyPi1Nqx0RExNyIW1X7uVNSPQSupWrJ38G0AEfES4F3AgcB+wDERsQcwHejKzElAV+39gAxaSdXS2zP4NrAXA/My8/HM7AZuBv4NOA7orH2mE5hS1JFBK6la6jSiBRYAh0bEmIjYHngD8FygLTNX1D7zMNBW1JEXwyRVSg5h1UFEtAPt/Q51ZGYHQGYujIhzgR8Ba4E7gX8aBmdmRkThDRIGraRqGcRFrnVqodoxwPlLgUsBIuIcYBmwMiLGZ+aKiBgPrCr6PU4dSKqW+k0dEBHjaj+fR9/87NXAHGBq7SNTgdlF/TiilVQt9b0z7PqIGAM8Bbw/M9dExJeAGRExDVgKnFDUiUErqVrqeMNCZm6w+1FmrgYmD6Ufg1ZStXgLriSVbAgXwxrFoJVUKZnu3iVJ5WrBTWUMWknV4tSBJJXMEa0klaznqWZXsAGDVlK1OHUgSSVz6kCSSuaIVpJKZtBKUrnSi2GSVDLnaCWpZE4dSFLJHNFKUskc0UpSyRzRSlLJut34W5LK1YIjWp+CK6laensH3wpExGkRcW9ELIiIayJiu4jYPSLmRcQDEXFdRIwo6seglVQtdXrceETsCnwQOCAzXwIMA04EzgW+mpl7AI8C04pKMmglVUsdR7T0Ta+OjIjhwPbACuBwYGbtfCcwpagTg1ZStQxhRBsR7RExv19rX99N5nLgPOD39AXsn4E7gDWZue6K2zJg16KSvBgmqVqGsOogMzuAjo2di4idgOOA3YE1wP8CRz2TkgxaSdWSWa+eXgv8LjMfAYiI7wCHADtGxPDaqHYisLyoI6cOJFVL/eZofw8cFBHbR0QAk4H7gBuBN9c+MxWYXdSRQSupWuoUtJk5j76LXr8C7qEvLzuA04EPR8QDwBjg0qKSnDqQVC11vGEhM88Cznra4cXAgUPpx6CVVC09Pc2uYAMGraRqcfcuSSqZQStJJWvBTWUMWkmVkr11W0dbNwatpGpx6kCSSuaqA0kqmSNaSSpZCwatt+CW5MoZ32XKf7yH4056N1deNwuAizqu4E3veC/HT30/7zr1DFY9srrJVarRvtnxFf6w7C7u/HXXBudOO/XddD+5nDFjdmpCZRWSOfjWIAZtCRYtXsL1c27gmksu4PrOr3Hzz37J75f9gZNPOp5ZV3yd6zsv5lWHvIKvX3Z1s0tVg11xxQyOPuakDY5PnDiBI157GEuXLmtCVRVT342/68KgLcHiJQ+x7z57MXK77Rg+fBgH7L8vP775NnYYNWr9Z5544m9ENLFINcWtP53Hnx5ds8Hxr5z3Gaaf8QWygaOsyurNwbcGKZyjjYgX0bf57bpdxJcDczJzYZmFbcn2eMHz+e+OTtb8+TGe9awR3Prz29nnRZMAuPB/LmfODV08e9QovnXRl5pcqVrBsce+juXLV3D33fc1u5RqaMFVBwOOaCPidOBaIIBf1loA10TE9AG+t/7xEJdccU09690ivHC35/HOk95C+2mf5D0f/jR7TXoB22zT97/6Q+/+T7pmXcnRr3sNV1//vSZXqmYbOXI7PnH6KXzm7POaXUplZG/voFujFI1opwH7ZOZT/Q9GxPnAvcBGh2T9Hw/x1B8Xb5X/Fjr+2CM5/tgjAbjgG5ezy7id/+n8Ma97De/96Jl84L/e3ozy1CJe+MLd2G235/Gr+XMBmDhxPLfP+yEHH3I0K1c+0uTqtlAteGdY0RxtLzBhI8fH185pE1bX5uFWPLyKrptv4w1HvJqlD/3jiRc/ufXn7P78ic0qTy1iwYLfMGHifuyx50HssedBLFu2gpe/4khDdnPU6XHj9VQ0oj0V6IqIRcBDtWPPA/YAPlBmYVu60874PGsee4zhw4fzyY+8j3959g6c+cULWPL7ZcQ2wYRdxnHmx05pdplqsG9feTGvOuxgdt55NEsWz+fsz57HZZdf2+yyqqUFR7RRdJUzIrahbzfx/hfDbs/MQc04b61TBxrYyAmHNrsEtaDuJ5dv9lqctWeeOOjMGfXZaxuy9qdw1UFm9gK/aEAtkrT5WnCbRNfRSqqWOq2jjYi9IuLOfu2xiDg1IkZHxNyIWFT7WXgrn0ErqVLqtbwrM+/PzP0zc3/gZcDjwCxgOtCVmZOArtr7ARm0kqqlnDvDJgMPZuZS+m7g6qwd7wSmFH3ZoJVULUMI2v43V9Va+yZ6PRFYd/dVW2auqL1+GGgrKsltEiVVyxBuwe1/c9WmRMQI4I3AJzby/YyIwqGxQSupUkp4ZtjrgV9l5sra+5URMT4zV0TEeGBVUQdOHUiqlvrP0b6Vf0wbAMwBptZeTwVmF3XgiFZStdRxs5iIGAUcAby73+EvATMiYhqwFDihqB+DVlK11HHqIDPXAmOedmw1fasQBs2glVQtLbjXgUErqVKyp/VuwTVoJVWLI1pJKlcJy7s2m0ErqVoMWkkqWetN0Rq0kqolu1svaQ1aSdXSejlr0EqqFi+GSVLZHNFKUrkc0UpS2RzRSlK5srvZFWzIoJVUKS34tHGDVlLFGLSSVC5HtJJUMoNWkkqWPdHsEjbgwxklVUr2Dr4ViYgdI2JmRPwmIhZGxMERMToi5kbEotrPnYr6MWglVUr2xqDbIFwI3JCZLwL2AxYC04GuzJwEdNXeD8iglVQp9RrRRsRzgMOASwEy88nMXAMcB3TWPtYJTCmqyaCVVCmZMegWEe0RMb9fa+/X1e7AI8BlEfHriLik9vjxtsxcUfvMw0BbUU1eDJNUKUNZdZCZHUDHJk4PB/4VOCUz50XEhTxtmiAzMyIKN1dwRCupUnp7YtCtwDJgWWbOq72fSV/wroyI8QC1n6uKOjJoJVVKvS6GZebDwEMRsVft0GTgPmAOMLV2bCowu6gmpw4kVcogVxMM1inAVRExAlgMnEzfAHVGREwDlgInFHVi0EqqlKzjdrSZeSdwwEZOTR5KPwatpEqp84i2LgxaSZWSadBKUql6WnCvA4NWUqU4opWkkjlHK0klq+eqg3oxaCVViiNaSSpZT2/r3fBq0EqqFKcOJKlkva46kKRyubxLkkq2VU4d7PPiwo1ttBV66c4vbHYJqiinDiSpZK46kKSSteDMgUErqVqcOpCkkrnqQJJKNoSH4DaMQSupUhJHtJJUqu46Th1ExBLgL0AP0J2ZB0TEaOA6YDdgCXBCZj46UD+ttw5CkjZDEoNug/SazNw/M9c9pHE60JWZk4Cu2vsBGbSSKqV3CO0ZOg7orL3uBKYUfcGglVQpQxnRRkR7RMzv19o36A5+FBF39DvXlpkraq8fBtqKanKOVlKlDGWkmpkdQMcAH3llZi6PiHHA3Ij4zdO+nxFReI+EQSupUnrquOogM5fXfq6KiFnAgcDKiBifmSsiYjywqqgfpw4kVUpvDL4NJCJGRcSz170GXgcsAOYAU2sfmwrMLqrJEa2kSumt34i2DZgVEdCXlVdn5g0RcTswIyKmAUuBwi0KDVpJlVKvTWUyczGw30aOrwYmD6Uvg1ZSpXgLriSVrDe8BVeSStXT7AI2wqCVVClFqwmawaCVVCl1XHVQNwatpErxUTaSVDKnDiSpZC7vkqSS9TiilaRyOaKVpJIZtJJUshZ82rhBK6laHNFKUsm8BVeSSuY6WkkqmVMHklQyg1aSStaKex34cEZJlVKvhzOuExHDIuLXEfH92vvdI2JeRDwQEddFxIiiPgxaSZXSM4Q2SB8CFvZ7fy7w1czcA3gUmFbUgUErqVJ6yUG3IhExETgauKT2PoDDgZm1j3QCU4r6MWglVUrvEFpEtEfE/H6t/WndXQB8nH9cYxsDrMnM7tr7ZcCuRTV5MUxSpQzlYlhmdgAdGzsXEccAqzLzjoh49ebUZNBKqpQ6Lu86BHhjRLwB2A74F+BCYMeIGF4b1U4Elhd15NSBpErpjhx0G0hmfiIzJ2bmbsCJwE8y8yTgRuDNtY9NBWYX1WTQSqqUHEJ7hk4HPhwRD9A3Z3tp0RecOpBUKWXcGZaZNwE31V4vBg4cyvcNWkmVMphlW41m0EqqlNaLWYNWUsW4qYwklaynBce0Bq2kSnFEK0klS0e0klQuR7RbkV0mtPHli89m57GjyUyuu3IWV3Rcy8fP+iCHH3kYTz75FA8tWcb0D57NXx77a7PLVQO0TRjHZy48g9FjR0Mms779Pa69dCbv+sjJTHnbMaz50xoALv7iN/nZT37R5Gq3XK24vCsyyy1qz7EHtN5/dQOMbRvD2Ladue/u+xk1anu+03Ul73vHR9llwjh+cet8enp6+OinTwHgvM9d1ORqG+85227f7BIabsy4MezcNob77/kt248ayRU3XMLH3nkGr33j4Tyx9gm+/Y1rm11i093+h1s2+9GK793thEFnzteXzGjIoxwd0ZbkkZWreWTlagDWrn2cB3+7hLbx47jtpnnrP3PXHfdw5LGTm1WiGmz1qtWsXtX3d+LxtU+w5IGljB0/tslVVU93C45o3eugAXZ97nj23ncv7rpjwT8dP/5tb+SWrp81qSo10/iJu7DXSyZx76/uA+AtJ7+Jq398GZ8+/3Se/Zwdmlzdli2H8KdRnnHQRsTJA5xbv5nun//2yDP9FZWw/aiRXHTZlznnU19h7V/Xrj/+ntPeSU93D3Nm/qCJ1akZRm4/knMv+Rznn3kRa//6ONd3fpc3HfxWTjrinfxx5WpOPev9zS5xizaUjb8bZXNGtGdv6kRmdmTmAZl5wHO223r/aTR8+DAuuuzLfG/mDfzo/25cf/xNJx7Da454JR9576eaWJ2aYdjwYZx7yee44TtzufEHtwDwpz8+Sm9vL5nJd6/6Pvvs/+ImV7lla8UR7YBztBFx96ZOAW31L6dazrngTB787e+47BtXrT926OEH864PvIOTjmvnb0/8vYnVqRk+/ZXTWbJoKVd3zFh/bMy4Mevnbl/9+kN58P7fNau8StgSl3e1AUfS96TH/gJwcnEAL3vFfkz596P5zb2LmH1jX9Ce/4Wv8alzPsqIEdty+cyLAbhz/gLO+tgXm1mqGmS/A/fl6LccxaL7HuSquX1bmF78xW9y5JTJ7LnPJDKTFcse5pyPn9fkSrdsPSWvpHomioL2+8AOmXnn009ExE2lVFQRd8y7iz3HHrDB8Zt/fFsTqlEruOuX9/DyCYdtcNw1s/XViutoBwzazNzk88oz8231L0eSNo+34EpSybbEOVpJ2qK04tSBNyxIqpR6Le+KiO0i4pcRcVdE3BsRZ9eO7x4R8yLigYi4LiJGFNVk0EqqlJ7MQbcCfwcOz8z9gP2BoyLiIOBc4KuZuQd9K7I2eS1rHYNWUqX0koNuA8k+67bW27bWEjgcmFk73glMKarJoJVUKUO5Bbf/dgG11t6/r4gYFhF3AquAucCDwJrM7K59ZBmwa1FNXgyTVClDWd6VmR1AxwDne4D9I2JHYBbwomdSk0ErqVLKWHWQmWsi4kbgYGDHiBheG9VOBJYXfd+pA0mVkpmDbgOJiLG1kSwRMRI4AlgI3Ai8ufaxqcDsopoc0UqqlDo+bnw80BkRw+gblM7IzO9HxH3AtRHxeeDXwKVFHRm0kiqlXlMHmXk38NKNHF8MHDiUvgxaSZVS9nMQnwmDVlKltOItuAatpEpx9y5JKtmWuPG3JG1RnDqQpJIZtJJUMlcdSFLJHNFKUslcdSBJJevJ1ntqmEErqVKco5WkkjlHK0klc45WkkrW69SBJJXLEa0klcxVB5JUMqcOJKlkrTh14MMZJVVKb+ag20Ai4rkRcWNE3BcR90bEh2rHR0fE3IhYVPu5U1FNBq2kSskh/CnQDXwkM/cGDgLeHxF7A9OBrsycBHTV3g/IqQNJldKTPXXpJzNXACtqr/8SEQuBXYHjgFfXPtYJ3AScPlBfjmglVUpmDrpFRHtEzO/X2jfWZ0TsRt8TcecBbbUQBngYaCuqyRGtpEoZyi24mdkBdAz0mYjYAbgeODUzH4uI/t/PiCj8hQatpEqp56YyEbEtfSF7VWZ+p3Z4ZUSMz8wVETEeWFXUj1MHkiqljqsOArgUWJiZ5/c7NQeYWns9FZhdVJMjWkmVUsd1tIcAbwfuiYg7a8fOAL4EzIiIacBS4ISijgxaSZVSr1twM/OnQGzi9OSh9GXQSqoUN/6WpJK514EklcwRrSSVzEfZSFLJHNFKUsnc+FuSSubFMEkqmVMHklSyVnzCgkErqVIc0UpSyVpxjjZaMf2rKiLaa/tfSuv596L63CaxsTa6e7u2ev69qDiDVpJKZtBKUskM2sZyHk4b49+LivNimCSVzBGtJJXMoJWkkhm0DRIRR0XE/RHxQERMb3Y9ar6I+FZErIqIBc2uReUyaBsgIoYBFwOvB/YG3hoReze3KrWAy4Gjml2EymfQNsaBwAOZuTgznwSuBY5rck1qssy8BfhTs+tQ+QzaxtgVeKjf+2W1Y5K2AgatJJXMoG2M5cBz+72fWDsmaStg0DbG7cCkiNg9IkYAJwJzmlyTpAYxaBsgM7uBDwA/BBYCMzLz3uZWpWaLiGuAnwN7RcSyiJjW7JpUDm/BlaSSOaKVpJIZtJJUMoNWkkpm0EpSyQxaSSqZQStJJTNoJalk/w+FIP4odXR4jQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iC3RE5jGiMq5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}